<!DOCTYPE html>
<html class="theme theme-black">
<head>
<meta charset="utf-8">
<title>推荐系统理论分析</title>
<link href="https://www.zybuluo.com/static/assets/template-theme-black.css" rel="stylesheet" media="screen">
<style type="text/css">

#wmd-preview h1  {
    color: #0077bb; /* 将标题改为蓝色 */
}</style>
</head>
<body class="theme theme-black">
<div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path id="MJMATHI-66" stroke-width="1" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path id="MJMAIN-28" stroke-width="1" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJMATHI-78" stroke-width="1" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJMAIN-29" stroke-width="1" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJMAIN-3D" stroke-width="1" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJMATHI-3B1" stroke-width="1" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path id="MJMAIN-2217" stroke-width="1" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path id="MJMATHI-6B" stroke-width="1" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJMATHI-57" stroke-width="1" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path><path id="MJMATHI-69" stroke-width="1" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-6A" stroke-width="1" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJMAIN-7C" stroke-width="1" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path id="MJMATHI-4E" stroke-width="1" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJSZ1-22C2" stroke-width="1" d="M139 -217Q127 -241 114 -246Q106 -249 97 -249Q67 -249 57 -220Q55 -214 55 102Q55 152 55 221T54 312Q54 422 60 464T91 554Q120 612 165 654T257 714T337 741T392 749Q393 750 402 750Q414 750 422 749Q557 749 660 659T776 430Q777 422 777 102Q777 -214 775 -220Q765 -249 735 -249Q716 -249 708 -241T694 -217L692 428L690 441Q674 540 597 603T416 666H409Q388 666 364 662T294 638T212 581Q156 523 142 441L140 428L139 105V-217Z"></path><path id="MJSZ2-22C2" stroke-width="1" d="M57 516Q68 602 104 675T190 797T301 882T423 933T542 949Q594 949 606 948Q780 928 901 815T1048 545Q1053 516 1053 475T1055 49Q1055 -406 1054 -410Q1051 -427 1037 -438T1006 -450T976 -439T958 -411Q957 -407 957 37Q957 484 956 494Q945 643 831 747T554 852Q481 852 411 826Q301 786 232 696T154 494Q153 484 153 37Q153 -407 152 -411Q148 -428 135 -439T104 -450T73 -439T56 -410Q55 -406 55 49Q56 505 57 516Z"></path><path id="MJSZ1-221A" stroke-width="1" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path><path id="MJSZ1-2211" stroke-width="1" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path id="MJMATHI-75" stroke-width="1" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-2208" stroke-width="1" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJMAIN-31" stroke-width="1" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJMATHI-6C" stroke-width="1" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJMATHI-6F" stroke-width="1" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJMATHI-67" stroke-width="1" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path id="MJMAIN-2B" stroke-width="1" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJMATHI-70" stroke-width="1" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJMAIN-2C" stroke-width="1" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJSZ2-2211" stroke-width="1" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path id="MJMATHI-53" stroke-width="1" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJMATHI-4B" stroke-width="1" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path><path id="MJMATHI-72" stroke-width="1" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-21" stroke-width="1" d="M78 661Q78 682 96 699T138 716T180 700T199 661Q199 654 179 432T158 206Q156 198 139 198Q121 198 119 206Q118 209 98 431T78 661ZM79 61Q79 89 97 105T141 121Q164 119 181 104T198 61Q198 31 181 16T139 1Q114 1 97 16T79 61Z"></path><path id="MJMAIN-5B" stroke-width="1" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path id="MJMATHI-6D" stroke-width="1" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-61" stroke-width="1" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJMATHI-65" stroke-width="1" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJMAIN-2E" stroke-width="1" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJMATHI-6E" stroke-width="1" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJMAIN-2212" stroke-width="1" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJMAIN-32" stroke-width="1" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJMAIN-39" stroke-width="1" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path id="MJMATHI-42" stroke-width="1" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path id="MJMAIN-5D" stroke-width="1" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path id="MJMAIN-36" stroke-width="1" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJMATHI-44" stroke-width="1" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path><path id="MJMATHI-63" stroke-width="1" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJMATHI-73" stroke-width="1" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJMATHI-64" stroke-width="1" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path id="MJMATHI-79" stroke-width="1" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJMATHI-74" stroke-width="1" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJMAIN-33" stroke-width="1" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJMAIN-201C" stroke-width="1" d="M128 494Q128 528 137 560T158 616T185 658T209 685T223 694T236 685T245 670Q244 668 231 654T204 622T178 571T164 501Q164 489 165 489T170 491T183 497T201 500Q226 500 244 483T262 440T245 397T202 379Q173 379 151 405T128 494ZM332 494Q332 528 341 560T362 616T389 658T413 685T427 694T439 685T449 672Q449 669 437 656T411 625T383 573T368 501Q368 489 369 489T374 491T387 497T405 500Q430 500 448 483T466 440T449 397T406 379Q377 379 355 405T332 494Z"></path><path id="MJMAIN-201D" stroke-width="1" d="M34 634Q34 659 50 676T93 694Q121 694 144 668T168 579Q168 525 146 476T101 403T73 379Q69 379 60 388T50 401Q50 404 62 417T88 448T116 500T131 572Q131 584 130 584T125 581T112 576T94 573Q69 573 52 590T34 634ZM238 634Q238 659 254 676T297 694Q325 694 348 668T372 579Q372 525 350 476T305 403T277 379Q273 379 264 388T254 401Q254 404 266 417T292 448T320 500T335 572Q335 584 334 584T329 581T316 576T298 573Q273 573 256 590T238 634Z"></path><path id="MJMAIN-34" stroke-width="1" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJMATHI-43" stroke-width="1" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJMATHI-55" stroke-width="1" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path><path id="MJMATHI-4C" stroke-width="1" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJMAIN-35" stroke-width="1" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path id="MJMAIN-37" stroke-width="1" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path><path id="MJMATHI-48" stroke-width="1" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs></svg></div><div id="wmd-preview" class="wmd-preview wmd-preview-full-reader"><div class="md-section-divider"></div><div class="md-section-divider"></div><h1 data-anchor-id="7c0h" id="推荐系统理论分析">推荐系统理论分析</h1><p data-anchor-id="c19r"><code class="code-black">未分类</code></p><hr><p data-anchor-id="zied"><div class="toc"><div class="toc">
<ul>
<li><a href="#推荐系统理论分析">推荐系统理论分析</a><ul>
<li><a href="#初级篇">初级篇</a><ul>
<li><a href="#一-基于用户行为数据进行推荐协同过滤">一. 基于用户行为数据进行推荐（协同过滤）</a><ul>
<li><a href="#11-用户行为数据">1.1 用户行为数据</a></li>
<li><a href="#12用户行为分析">1.2用户行为分析</a><ul>
<li><a href="#121-用户活跃度和物品流行度的关系">1.2.1 用户活跃度和物品流行度的关系</a></li>
</ul>
</li>
<li><a href="#13协同过滤">1.3协同过滤</a><ul>
<li><a href="#131-基于用户的协同过滤算法usercf">1.3.1 基于用户的协同过滤算法(UserCF)</a></li>
<li><a href="#132-基于物品的协同过滤算法itemcf">1.3.2 基于物品的协同过滤算法（ItemCF）</a></li>
<li><a href="#133-usercf和itemcf的比较">1.3.3 UserCF和ItemCF的比较</a></li>
<li><a href="#134-隐语义模型">1.3.4 隐语义模型</a></li>
<li><a href="#135-基于图的模型">1.3.5 基于图的模型</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#二-利用标签数据进行推荐">二. 利用标签数据进行推荐</a><ul>
<li><a href="#21-ugc标签简介">2.1. UGC标签简介</a><ul>
<li><a href="#211-用户为什么要标注">2.1.1 用户为什么要标注</a></li>
<li><a href="#212-用户如何打标签">2.1.2 用户如何打标签</a></li>
<li><a href="#213-用户打什么样的标签">2.1.3 用户打什么样的标签</a></li>
</ul>
</li>
<li><a href="#22-基于标签的推荐">2.2 基于标签的推荐</a><ul>
<li><a href="#221-一个最简单的算法">2.2.1 一个最简单的算法</a></li>
<li><a href="#222-基于tfidf的算法改进">2.2.2 基于TFIDF的算法改进</a></li>
<li><a href="#223-标签扩充">2.2.3 标签扩充</a></li>
<li><a href="#224-标签清理">2.2.4 标签清理</a></li>
<li><a href="#225-基于图的推荐算法">2.2.5 基于图的推荐算法</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#三-利用上下文信息进行推荐">三. 利用上下文信息进行推荐</a></li>
<li><a href="#四-利用社交网络数据进行推荐">四. 利用社交网络数据进行推荐</a></li>
<li><a href="#五-冷启动问题">五. 冷启动问题</a></li>
<li><a href="#六-评分预测问题">六. 评分预测问题</a></li>
<li><a href="#七-ee问题及基本bandit算法">七. EE问题及基本Bandit算法</a></li>
<li><a href="#八-推荐系统中的常用评测指标">八. 推荐系统中的常用评测指标</a><ul>
<li><a href="#81-精确率召回率f1值">8.1 精确率、召回率、F1值</a></li>
<li><a href="#82-auc曲线">8.2 AUC曲线</a></li>
<li><a href="#83-hit-ratiohr">8.3 Hit Ratio(HR)</a></li>
<li><a href="#84-mean-average-precisionmap">8.4 Mean Average Precision(MAP)</a></li>
<li><a href="#85-normalized-discounted-cummulative-gainndcg">8.5 Normalized Discounted Cummulative Gain(NDCG)</a></li>
<li><a href="#86-mean-reciprocal-rank-mrr">8.6 Mean Reciprocal Rank (MRR)</a></li>
<li><a href="#87-ils">8.7 ILS</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#高级篇">高级篇</a><ul>
<li><a href="#一fm模型理论和实践">一.FM模型理论和实践</a><ul>
<li><a href="#11-fm背景">1.1 FM背景</a></li>
<li><a href="#12-one-hot编码带来的问题">1.2 one-hot编码带来的问题</a></li>
<li><a href="#13-对特征进行组合">1.3 对特征进行组合</a></li>
<li><a href="#14-fm求解">1.4 FM求解</a></li>
</ul>
</li>
<li><a href="#二ffm模型理论和实践">二.FFM模型理论和实践</a></li>
<li><a href="#三deepfm模型理论和实践">三.DeepFM模型理论和实践</a></li>
<li><a href="#四多值离散特征的embedding解决方案">四.多值离散特征的embedding解决方案</a></li>
<li><a href="#五deepcross-network模型理论和实践">五.Deep&amp;Cross Network模型理论和实践</a></li>
<li><a href="#六pnn模型理论和实践">六.PNN模型理论和实践</a></li>
<li><a href="#七nfm模型理论和实践">七.NFM模型理论和实践</a></li>
<li><a href="#八afm模型理论和实践">八.AFM模型理论和实践</a></li>
<li><a href="#九gbdtlr融合方案实战">九.GBDT+LR融合方案实战</a></li>
<li><a href="#十神经协同过滤ncf原理及实战">十.神经协同过滤NCF原理及实战</a></li>
<li><a href="#十一基于强化学习的推荐理论与实践">十一.基于强化学习的推荐理论与实践</a></li>
<li><a href="#十二贝叶斯个性化排序bpr算法原理及实战">十二.贝叶斯个性化排序(BPR)算法原理及实战</a></li>
<li><a href="#十三深度兴趣进化网络dien原理及实战">十三.深度兴趣进化网络DIEN原理及实战</a></li>
<li><a href="#十四知识图谱与推荐系统结合之dkn模型原理及实现">十四.知识图谱与推荐系统结合之DKN模型原理及实现</a></li>
<li><a href="#十五知识图谱与推荐系统结合之ripplenet模型原理及实现">十五.知识图谱与推荐系统结合之RippleNet模型原理及实现</a></li>
<li><a href="#十六知识图谱与推荐系统结合之mkr模型原理及实现">十六.知识图谱与推荐系统结合之MKR模型原理及实现</a></li>
<li><a href="#十七协同记忆网络理论及实践">十七.协同记忆网络理论及实践</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</p><hr><div class="md-section-divider"></div><h2 data-anchor-id="do12" id="初级篇">初级篇</h2><div class="md-section-divider"></div><h3 data-anchor-id="z0rl" id="一-基于用户行为数据进行推荐协同过滤">一. 基于用户行为数据进行推荐（协同过滤）</h3><div class="md-section-divider"></div><h4 data-anchor-id="eeh6" id="11-用户行为数据">1.1 用户行为数据</h4><p data-anchor-id="ivja">用户行为数据在网站上最简单的存在形式就是日志，比如用户在电子商务网站中的网页浏览、购买、点击、评分和评论等活动。 <br>
用户行为在个性化推荐系统中一般分两种：</p><pre data-anchor-id="02ex" class="code-black"><code class="code-black">显性反馈行为(explicit feedback)
隐性反馈行为(implicitfeedback)
</code></pre><p data-anchor-id="48ds">显性反馈行为包括用户明确表示对物品喜好的行为。网站中收集显性反馈的主要方式就是评分和喜欢/不喜欢。隐性反馈行为指的是那些不能明确反应用户喜好 的行为。最具代表性的隐性反馈行为就是页面浏览行为。 <br>
按照反馈的明确性分，用户行为数据可以分为显性反馈和隐性反馈，但按照反馈的方向分， 又可以分为正反馈和负反馈。</p><pre data-anchor-id="co54" class="code-black"><code class="code-black">正反馈指用户的行为倾向于指用户喜欢该物品
负反馈指用户的 行为倾向于指用户不喜欢该物品
</code></pre><p data-anchor-id="rgkw">在显性反馈中，很容易区分一个用户行为是正反馈还是负反馈， 而在隐性反馈行为中，就相对比较难以确定。</p><div class="md-section-divider"></div><h4 data-anchor-id="v10w" id="12用户行为分析">1.2用户行为分析</h4><p data-anchor-id="o6yt">很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law3的分布，这个分布在互联网领域也称长尾分布。 <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -924.3828982726751 5862.756186388786 1195.4345836206996" style="width: 13.668ex; height: 2.78ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-66"></use><use xlink:href="#MJMAIN-28" x="550" y="0"></use><use xlink:href="#MJMATHI-78" x="940" y="0"></use><use xlink:href="#MJMAIN-29" x="1512" y="0"></use><use xlink:href="#MJMAIN-3D" x="2179" y="0"></use><use xlink:href="#MJMATHI-3B1" x="3236" y="0"></use><use xlink:href="#MJMAIN-2217" x="4098" y="0"></use><g transform="translate(4821,0)"><use xlink:href="#MJMATHI-78"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6B" x="809" y="583"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1">f(x)=\alpha*x^k</script> <br>
如果定义物品的流行度K为被K个用户产生过行为，而用户的活跃度K定义为对K个物品产生过行为，那么二者的分布大概如下图所示(横轴代表物品的流行度／用户的活跃度，纵轴代表物品数／用户数）： <br>
<img src="http://static.zybuluo.com/binbinmeng/1arrvdvct1idgkulaqmhzmxl/image.png" alt="image.png-106.8kB"> <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -618.5051216414607 7181.441235521236 887.9124054450837" style="width: 16.68ex; height: 2.085ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">物</text><g transform="translate(797,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">品</text></g><g transform="translate(1595,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">流</text></g><g transform="translate(2393,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">行</text></g><g transform="translate(3191,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">度</text></g><g transform="translate(3989,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">长</text></g><g transform="translate(4787,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">尾</text></g><g transform="translate(5585,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">分</text></g><g transform="translate(6383,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">布</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">物品流行度长尾分布</script> <br>
<img src="http://static.zybuluo.com/binbinmeng/vfirplblikcx0r0di3mcf3hp/image.png" alt="image.png-99.8kB"> <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -618.5051216414607 7181.441235521236 887.9124054450837" style="width: 16.68ex; height: 2.085ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">用</text><g transform="translate(797,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">户</text></g><g transform="translate(1595,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">活</text></g><g transform="translate(2393,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">跃</text></g><g transform="translate(3191,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">度</text></g><g transform="translate(3989,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">长</text></g><g transform="translate(4787,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">尾</text></g><g transform="translate(5585,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">分</text></g><g transform="translate(6383,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">布</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-3">用户活跃度长尾分布</script> <br>
可以看到，不管是物品的流行度还是用户的活跃度，都近似于长尾分布。</p><div class="md-section-divider"></div><h5 data-anchor-id="nav5" id="121-用户活跃度和物品流行度的关系">1.2.1 用户活跃度和物品流行度的关系</h5><p data-anchor-id="i6ev">一般认为，新用户倾向于浏览热门的物品，因为他 们对网站还不熟悉，只能点击首页的热门物品，而老用户会逐渐开始浏览冷门的物品。如果用横坐标表示用户活跃度，纵坐标表示具有某个活跃度的所有用户评过分的物品的平均流行度。图中曲线呈明显下 降的趋势，这表明用户越活跃，越倾向于浏览冷门的物品。 <br>
<img src="http://static.zybuluo.com/binbinmeng/ig8ksgwx4qmotm7dq3nueipl/image.png" alt="image.png-99.6kB"></p><div class="md-section-divider"></div><h4 data-anchor-id="3l2a" id="13协同过滤">1.3协同过滤</h4><p data-anchor-id="h63x">仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法。学术界对协同过滤算法进行了深入研究，提出了很多方法，比如：</p><pre data-anchor-id="2wfg" class="code-black"><code class="code-black">&lt;1&gt;基于邻域的方法(neighborhood-based)
&lt;2&gt;隐语义模型 (latent factor model)
&lt;3&gt;基于图的随机游走算法(random walk on graph)等
</code></pre><p data-anchor-id="xdeb">在这些方法中， 最著名的、在业界得到最广泛应用的算法是基于邻域的方法，而基于邻域的方法主要包含下面两种算法：</p><pre data-anchor-id="bay3" class="code-black"><code class="code-black">1、基于用户的协同过滤算法：这种算法给用户推荐和他兴趣相似的其他用户喜欢的物品。
2、基于物品的协同过滤算法：这种算法给用户推荐和他之前喜欢的物品相似的物品。
</code></pre><div class="md-section-divider"></div><h5 data-anchor-id="0e9x" id="131-基于用户的协同过滤算法usercf">1.3.1 基于用户的协同过滤算法(UserCF)</h5><p data-anchor-id="y99d">UserCF在一些网站(如Digg)中得到了应用，但该算法有一些缺点。首先， 随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。其次，基于用户的协同过滤很难对推荐结果作出解释。因此，著名的电子商务公司亚马逊提出了另一个算法——基于物品的协同过滤算法。</p><div class="md-section-divider"></div><h5 data-anchor-id="co04" id="132-基于物品的协同过滤算法itemcf">1.3.2 基于物品的协同过滤算法（ItemCF）</h5><p data-anchor-id="4sjp">基于物品的协同过滤算法(简称ItemCF)给用户推荐那些和他们之前喜欢的物品相似的物品。 比如，该算法会因为你购买过《数据挖掘导论》而给你推荐《机器学习》。不过，ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。 <br>
基于物品的协同过滤算法主要分为两步。</p><pre data-anchor-id="udtg" class="code-black"><code class="code-black">(1) 计算物品之间的相似度。
(2) 根据物品的相似度和用户的历史行为给用户生成推荐列表。
</code></pre><p data-anchor-id="nvle">ItemCF的第一步是计算物品之间的相似度，在网站中，我们经常看到这么一句话：Customers Who Bought This Item Also Bought，那么从这句话的定义出发，我们可以用下面的公式定义物品相似度： <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1487.2294845758236 9648.375829028291 2473.958969151647" style="width: 22.355ex; height: 5.792ex; vertical-align: -2.432ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-57"></use><g transform="translate(944,-150)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-69"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6A" x="345" y="0"></use></g><use xlink:href="#MJMAIN-3D" x="1858" y="0"></use><g transform="translate(3034,0)"><rect stroke="none" width="6493" height="60" x="0" y="220"></rect><g transform="translate(60,715)"><use xlink:href="#MJMAIN-7C"></use><use xlink:href="#MJMATHI-4E" x="278" y="0"></use><use xlink:href="#MJMAIN-28" x="1167" y="0"></use><use xlink:href="#MJMATHI-69" x="1556" y="0"></use><use xlink:href="#MJMAIN-29" x="1902" y="0"></use><use xlink:href="#MJMAIN-7C" x="2291" y="0"></use><use xlink:href="#MJSZ1-22C2" x="2736" y="0"></use><use xlink:href="#MJMAIN-7C" x="3736" y="0"></use><use xlink:href="#MJMATHI-4E" x="4015" y="0"></use><use xlink:href="#MJMAIN-28" x="4903" y="0"></use><use xlink:href="#MJMATHI-6A" x="5293" y="0"></use><use xlink:href="#MJMAIN-29" x="5705" y="0"></use><use xlink:href="#MJMAIN-7C" x="6095" y="0"></use></g><g transform="translate(1961,-716)"><use xlink:href="#MJMAIN-7C"></use><use xlink:href="#MJMATHI-4E" x="278" y="0"></use><use xlink:href="#MJMAIN-28" x="1167" y="0"></use><use xlink:href="#MJMATHI-69" x="1556" y="0"></use><use xlink:href="#MJMAIN-29" x="1902" y="0"></use><use xlink:href="#MJMAIN-7C" x="2291" y="0"></use></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-4">W_{ij}=\frac{|N(i)|\bigcap|N(j)|}{|N(i)|}</script> <br>
这里，分母|N(i)|是喜欢物品i的用户数，而分子 <span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -969.0516853480245 6651.833333333333 1442.103370696049" style="width: 15.405ex; height: 3.359ex; vertical-align: -1.158ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMAIN-7C"></use><use xlink:href="#MJMATHI-4E" x="278" y="0"></use><use xlink:href="#MJMAIN-28" x="1167" y="0"></use><use xlink:href="#MJMATHI-69" x="1556" y="0"></use><use xlink:href="#MJMAIN-29" x="1902" y="0"></use><use xlink:href="#MJMAIN-7C" x="2291" y="0"></use><use xlink:href="#MJSZ2-22C2" x="2736" y="-1"></use><use xlink:href="#MJMAIN-7C" x="4014" y="0"></use><use xlink:href="#MJMATHI-4E" x="4293" y="0"></use><use xlink:href="#MJMAIN-28" x="5181" y="0"></use><use xlink:href="#MJMATHI-6A" x="5571" y="0"></use><use xlink:href="#MJMAIN-29" x="5983" y="0"></use><use xlink:href="#MJMAIN-7C" x="6373" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-5">|N(i)|\bigcap|N(j)|</script> 是同时喜欢物品i和物品j的用户 数。因此，上述公式可以理解为喜欢物品i的用户中有多少比例的用户也喜欢物品j。但是却存在一个问题。如果物品j很热门，很多人都喜欢， <br>
那么Wij就会很大，接近1。因此，该公式会造成任何物品都会和热门的物品有很大的相似度，这 对于致力于挖掘长尾信息的推荐系统来说显然不是一个好的特性。为了避免推荐出热门的物品，可以用下面的公式: <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-6-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1487.2294845758236 10039.04249569496 2733.958969151647" style="width: 23.282ex; height: 6.371ex; vertical-align: -3.012ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-57"></use><g transform="translate(944,-150)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-69"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6A" x="345" y="0"></use></g><use xlink:href="#MJMAIN-3D" x="1858" y="0"></use><g transform="translate(3034,0)"><rect stroke="none" width="6884" height="60" x="0" y="220"></rect><g transform="translate(255,715)"><use xlink:href="#MJMAIN-7C"></use><use xlink:href="#MJMATHI-4E" x="278" y="0"></use><use xlink:href="#MJMAIN-28" x="1167" y="0"></use><use xlink:href="#MJMATHI-69" x="1556" y="0"></use><use xlink:href="#MJMAIN-29" x="1902" y="0"></use><use xlink:href="#MJMAIN-7C" x="2291" y="0"></use><use xlink:href="#MJSZ1-22C2" x="2736" y="0"></use><use xlink:href="#MJMAIN-7C" x="3736" y="0"></use><use xlink:href="#MJMATHI-4E" x="4015" y="0"></use><use xlink:href="#MJMAIN-28" x="4903" y="0"></use><use xlink:href="#MJMATHI-6A" x="5293" y="0"></use><use xlink:href="#MJMAIN-29" x="5705" y="0"></use><use xlink:href="#MJMAIN-7C" x="6095" y="0"></use></g><g transform="translate(60,-899)"><use xlink:href="#MJSZ1-221A" x="0" y="22"></use><rect stroke="none" width="5764" height="60" x="1000" y="813"></rect><g transform="translate(1000,0)"><use xlink:href="#MJMAIN-7C"></use><use xlink:href="#MJMATHI-4E" x="278" y="0"></use><use xlink:href="#MJMAIN-28" x="1167" y="0"></use><use xlink:href="#MJMATHI-69" x="1556" y="0"></use><use xlink:href="#MJMAIN-29" x="1902" y="0"></use><use xlink:href="#MJMAIN-7C" x="2291" y="0"></use><use xlink:href="#MJMAIN-7C" x="2570" y="0"></use><use xlink:href="#MJMAIN-7C" x="2848" y="0"></use><use xlink:href="#MJMAIN-7C" x="3127" y="0"></use><use xlink:href="#MJMATHI-4E" x="3405" y="0"></use><use xlink:href="#MJMAIN-28" x="4294" y="0"></use><use xlink:href="#MJMATHI-6A" x="4683" y="0"></use><use xlink:href="#MJMAIN-29" x="5096" y="0"></use><use xlink:href="#MJMAIN-7C" x="5485" y="0"></use></g></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-6">W_{ij}=\frac{|N(i)|\bigcap|N(j)|}{\sqrt{|N(i)||||N(j)|}}</script> <br>
这里由于还是0-1的原因，我们的余弦相似度可以写成上面的形式。但是，是不是每个用户的贡献都相同呢? 假设有这么一个用户，他是开书店的，并且买了当当网上80%的书准备用来自己卖。那么， 他的购物车里包含当当网80%的书。假设当当网有100万本书，也就是说他买了80万本。从前面 对ItemCF的讨论可以看到，这意味着因为存在这么一个用户，有80万本书两两之间就产生了相似度。这个用户虽然活跃，但是买这些书并非都是出于自身的兴趣，而且这些书覆 盖了当当网图书的很多领域，所以这个用户对于他所购买书的两两相似度的贡献应该远远小于一个只买了十几本自己喜欢的书的文学青年。因此，我们要对这样的用户进行一定的惩罚，John S. Breese在论文1中提出了一个称为IUF(Inverse User Frequence)，即用户活跃度对数的 倒数的参数，他也认为活跃用户对物品相似度的贡献应该小于不活跃的用户，他提出应该增加IUF参数来修正物品相似度的计算公式: <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-7-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -1972.614507999057 10907.036208234511 3219.3439925748808" style="width: 25.367ex; height: 7.529ex; vertical-align: -3.012ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(120,0)"><rect stroke="none" width="10667" height="60" x="0" y="220"></rect><g transform="translate(60,1076)"><use xlink:href="#MJSZ1-2211"></use><g transform="translate(1056,-287)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-75"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2208" x="572" y="0"></use><g transform="translate(876,0)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-4E" x="278" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-28" x="1167" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-69" x="1556" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-29" x="1902" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C" x="2291" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJSZ1-22C2" x="2805" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C" x="3874" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-4E" x="4153" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-28" x="5041" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6A" x="5431" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-29" x="5843" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C" x="6233" y="0"></use></g></g><g transform="translate(6804,0)"><g transform="translate(120,0)"><rect stroke="none" width="3502" height="60" x="0" y="220"></rect><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-31" x="2226" y="571"></use><g transform="translate(60,-435)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6C"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6F" x="298" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-67" x="784" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-31" x="1264" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2B" x="1764" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-4E" x="2543" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-28" x="3432" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-75" x="3821" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-29" x="4394" y="0"></use></g></g></g></g><g transform="translate(1951,-899)"><use xlink:href="#MJSZ1-221A" x="0" y="22"></use><rect stroke="none" width="5764" height="60" x="1000" y="813"></rect><g transform="translate(1000,0)"><use xlink:href="#MJMAIN-7C"></use><use xlink:href="#MJMATHI-4E" x="278" y="0"></use><use xlink:href="#MJMAIN-28" x="1167" y="0"></use><use xlink:href="#MJMATHI-69" x="1556" y="0"></use><use xlink:href="#MJMAIN-29" x="1902" y="0"></use><use xlink:href="#MJMAIN-7C" x="2291" y="0"></use><use xlink:href="#MJMAIN-7C" x="2570" y="0"></use><use xlink:href="#MJMAIN-7C" x="2848" y="0"></use><use xlink:href="#MJMAIN-7C" x="3127" y="0"></use><use xlink:href="#MJMATHI-4E" x="3405" y="0"></use><use xlink:href="#MJMAIN-28" x="4294" y="0"></use><use xlink:href="#MJMATHI-6A" x="4683" y="0"></use><use xlink:href="#MJMAIN-29" x="5096" y="0"></use><use xlink:href="#MJMAIN-7C" x="5485" y="0"></use></g></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-7">\frac{\sum_{u\in{|N(i)|\bigcap|N(j)|}}{\frac{1}{log1+N(u)}}}{\sqrt{|N(i)||||N(j)|}}</script> <br>
在得到物品之间的相似度后，ItemCF通过如下公式计算用户u对一个物品j的兴趣: <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-8-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="-38.5 -971.0516853480245 11952.760631879626 2417.790365444969" style="width: 27.799ex; height: 5.56ex; vertical-align: -3.475ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#MJMATHI-70"></use><g transform="translate(503,-150)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-75"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2C" x="572" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6A" x="851" y="0"></use></g><use xlink:href="#MJMAIN-3D" x="1774" y="0"></use><g transform="translate(2830,0)"><use xlink:href="#MJSZ2-2211" x="2345" y="0"></use><g transform="translate(0,-1150)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-69"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2208" x="345" y="0"></use><g transform="translate(716,0)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-4E" x="278" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-28" x="1167" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-75" x="1556" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-29" x="2129" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C" x="2518" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJSZ1-22C2" x="3032" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C" x="4101" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-53" x="4380" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-28" x="5025" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6A" x="5415" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-2C" x="5827" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-4B" x="6106" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-29" x="6995" y="0"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMAIN-7C" x="7385" y="0"></use></g></g></g><g transform="translate(9133,0)"><use xlink:href="#MJMATHI-57"></use><g transform="translate(944,-150)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-6A"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-69" x="412" y="0"></use></g><g transform="translate(1580,0)"><use xlink:href="#MJMATHI-72"></use><g transform="translate(451,-150)"><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-75"></use><use transform="scale(0.7071067811865476)" xlink:href="#MJMATHI-69" x="572" y="0"></use></g></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-8">p_{u,j}=\sum_{i\in{|N(u)|\bigcap|S(j,K)|}}{W_{ji}r_{ui}}</script> <br>
其中，</p><pre data-anchor-id="gkjg" class="code-black"><code class="code-black">N(u)是用户喜欢的物品的集合，
S(j,K)是和物品j最相似的K个物品的集合，
Wji是物品j和i 的相似度，
rui是用户u对物品i的兴趣
</code></pre><div class="md-section-divider"></div><h5 data-anchor-id="cfuk" id="133-usercf和itemcf的比较">1.3.3 UserCF和ItemCF的比较</h5><p data-anchor-id="cd85">首先我们提出一个问题，为什么新闻网站一般使用UserCF，而图书、电商网站一般使用ItemCF呢？ <br>
首先回顾一下UserCF算法和ItemCF算法的推荐原理。UserCF给用户推荐那些和他有共同兴 趣爱好的用户喜欢的物品，而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算 法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF 的推荐结果着重于维系用户的历史兴趣。换句话说，UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。 <br>
在新闻网站中，用户的兴趣不是特别细化，绝大多数用户都喜欢看热门的新闻。个性化新闻推荐更加强调抓住 新闻热点，热门程度和时效性是个性化新闻推荐的重点，而个性化相对于这两点略显次要。因 此，UserCF可以给用户推荐和他有相似爱好的一群其他用户今天都在看的新闻，这样在抓住热 点和时效性的同时，保证了一定程度的个性化。同时，在新闻网站中，物品的更新速度远远快于新用户的加入速度，而且 对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。 <br>
但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发 挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。一个技术人员可能都是在购买 技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上越是资深的技术人员，他们看 的书就越可能不热门。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的 好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的 任务是帮助用户发现和他研究领域相关的物品。因此，ItemCF算法成为了这些网站的首选算法。 此外，这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成 太大的损失，是可以接受的。同时，从技术上考虑，UserCF需要维护一个用户相似度的矩阵，而ItemCF需要维护一个物品 相似度矩阵。从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间， 同理，如果物品很多，那么维护物品相似度矩阵代价较大。 <br>
下表是对二者的一个全面的比较： <br>
<img src="http://static.zybuluo.com/binbinmeng/w71rfsvss7ws3ge25ado3lxf/%E6%8D%95%E8%8E%B71.PNG" alt="捕获1.PNG-402kB"></p><div class="md-section-divider"></div><h5 data-anchor-id="psqf" id="134-隐语义模型">1.3.4 隐语义模型</h5><p data-anchor-id="8grt">隐语义模型是最近几年推荐系统领域最为热门的研究话题，它的核心思想是通过隐含特征 (latent factor)联系用户兴趣和物品。 <br>
使用隐语义模型的基本思路是：对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。那么这个方法大概需要解决三个问题：</p><pre data-anchor-id="97c9" class="code-black"><code class="code-black">1、如何给物品进行分类?
2、如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度?
3、对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重?
</code></pre><p data-anchor-id="phdg">隐含语义分析技术从诞生到今天产生了很多著名的模型和方法，其中和该技术相关且耳熟能 详的名词有pLSA、LDA、隐含类别模型(latent class model)、隐含主题模型(latent topic model)、 隐因子模型(Latent Factor Model），矩阵分解(matrix factorization)。这些技术和方法在本质上是相通的，其中很多方法都可以用于 个性化推荐系统。我们将以LFM为例介绍隐含语义分析技术在推荐系统中的应用。 <br>
在推荐系统中它能够基于用户的行为对item进行自动聚类，也就是把item划分到不同类别/主题，这些主题/类别可以理解为用户的兴趣。 <br>
对于一个给定的用户行为数据集（数据集包含的是所有的user, 所有的item，以及每个user有过行为的item列表），使用LFM对其建模后，我们可以得到如下图所示的模型：（假设数据集中有3个user, 4个item, LFM建模的分类数为4） <br>
<img src="http://static.zybuluo.com/binbinmeng/xbt6zeaanhxyprmyg30npv8h/image.png" alt="image.png-15.2kB"> <br>
R矩阵是user-item矩阵，矩阵值Rij表示的是user i 对item j的兴趣度，这正是我们要求的值。对于一个user来说，当计算出他对所有item的兴趣度后，就可以进行排序并作出推荐。LFM算法从数据集中抽取出若干主题，作为user和item之间连接的桥梁，将R矩阵表示为P矩阵和Q矩阵相乘。其中P矩阵是user-class矩阵，矩阵值Pij表示的是user i对class j的兴趣度；Q矩阵式class-item矩阵，矩阵值Qij表示的是item  <br>
j在class i中的权重，权重越高越能作为该类的代表。</p><p data-anchor-id="0kpq">LFM通过如下公式计算用户u对物品i的兴趣: <br>
<img src="http://static.zybuluo.com/binbinmeng/ahd1uz1h2ecxxbthsxuxmtdn/image.png" alt="image.png-12.3kB" title=""> <br>
这个公式中 P_u,k 和 Q_i,k 是模型的参数，其中:</p><pre data-anchor-id="i8t5" class="code-black"><code class="code-black">1. P_u,k 度量了用户u的兴趣和第k个隐类的关系，
2. Q_i,k 度量了第k个隐类和物品i之间的关系
</code></pre><p data-anchor-id="boul">那么，下面的问题就是如何计算这两个参数。 <br>
我们发现使用LFM后，&nbsp;</p><p data-anchor-id="u6i6">我们不需要关心分类的角度，结果都是基于用户行为统计自动聚类的，全凭数据自己说了算。 <br>
不需要关心分类粒度的问题，通过设置LFM的最终分类数就可控制粒度，分类数越大，粒度约细。 <br>
对于一个item，并不是明确的划分到某一类，而是计算其属于每一类的概率，是一种标准的软分类。 <br>
对于一个user，我们可以得到他对于每一类的兴趣度，而不是只关心可见列表中的那几个类。 <br>
对于每一个class，我们可以得到类中每个item的权重，越能代表这个类的item，权重越高。 <br>
那么，接下去的问题就是如何计算矩阵P和矩阵Q中参数值。一般做法就是最优化损失函数来求参数。在定义损失函数之前，我们需要准备一下数据集并对兴趣度的取值做一说明。 <br>
数据集应该包含所有的user和他们有过行为的（也就是喜欢）的item。所有的这些item构成了一个item全集。对于每个user来说，我们把他有过行为的item称为正样本，规定兴趣度RUI=1，此外我们还需要从item全集中随机抽样，选取与正样本数量相当的样本作为负样本，规定兴趣度为RUI=0。因此，兴趣的取值范围为[0,1]。</p><p data-anchor-id="8qgl">采样之后原有的数据集得到扩充，得到一个新的user-item集K={(U,I)}，其中如果(U,I)是正样本，则RUI=1，否则RUI=0。损失函数如上面所示：</p><p data-anchor-id="940e">这两个参数是从数据集中通过最优化理论（机器学习算法）计算出来的。要计算这两个参数，需要一个训练集，对于每个用户u，训练 集里都包含了用户u喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。我们可以通过最小化下面的损失函数来得到最合适的p和q： <br>
<img src="http://static.zybuluo.com/binbinmeng/k07lneobfijeashuv5it00be/image.png" alt="image.png-25.7kB" title=""> <br>
上面的式子中，后面的两项是为了防止过拟合的正则化项，求解上面的式子可以使用随机梯度下降来得到，这里就不再赘述。 <br>
综上所述，执行LFM需要：</p><pre data-anchor-id="a1aw" class="code-black"><code class="code-black">1. 根据数据集初始化P和Q矩阵（这是我暂时没有弄懂的地方，这个初始化过程到底是怎么样进行的，还恳请各位童鞋予以赐教。）
2. 确定4个参数：分类数F，迭代次数N，学习速率α，正则化参数λ。
</code></pre><p data-anchor-id="1iws">LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐。经典的LFM模型 每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户隐类向量(pu)和物品隐类向 量(qi)。而且LFM的训练需要在用户行为记录上反复迭代才能获得比较好的性能。</p><div class="md-section-divider"></div><h5 data-anchor-id="lerv" id="135-基于图的模型">1.3.5 基于图的模型</h5><p data-anchor-id="7l7b"><img src="http://static.zybuluo.com/binbinmeng/cah3xlzpebgan4u8oevqih8w/image.png" alt="image.png-45.5kB"> <br>
<img src="http://static.zybuluo.com/binbinmeng/mkufvt81iqp0jr2m1uvn2zo7/image.png" alt="image.png-47.1kB"> <br>
基于随机游走的PersonalRank算法</p><pre data-anchor-id="q9ok" class="code-black"><code class="code-black">在基于图的模型中，给用户A进行个性化推荐，实际是计算用户A对所有物品的感兴趣程度。
在PersonalRank算法中，不区分用户和商品，所以计算用户A对所有物品的感兴趣程度，即计算除用户A外的所有节点B，C，D，a，b，c，d，e对用户A的重要度。
</code></pre><p data-anchor-id="yo32">如上图所示，用户A和物品c、 e没有边相连，但是用户A和物品c有一条长度为3的路径相连（A, a, B, c），用户A和物品e有两条长度为3的路径相连。那么，顶点A与e之间的相关性要高于顶点A与c，因而物品e在用户A的推荐列表中应该排在物品c之前，因为顶点A与e之间有两条路径——(A, b, C, e)和(A, d, D, e) 。其中，(A, b, C, e)路径经过的顶点的出度为(3, 2, 2, 2) ，而(A, d, D, e)路径经过的顶点的出度为(3, 2, 3, 2) 。 <br>
因此，(A, d, D, e)经过了一个出度比较大的顶点D，所以(A, d, D, e)对顶点A与e之间相关性的贡献要小于(A, b, C, e) 。简而言之就是求A到e和A到c在线相连的长度谁更短，且是否经过热门中转点来计算权重求得两者的相关性大小。 <br>
有种基于随机游走的PersonalRank算法，可以计算图中顶点之间相关性。假设要给用户u进行个性化推荐，可以从用户u对应的节点vu开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率α决定是继续游走，还是停止这次游走并从vu节点开始重新游走。 <br>
如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。 <br>
如果将上面的描述表示成公式，可以得到如下公式： <br>
其中PR(v)表示重要度（物品结点的访问概率） <br>
<img src="http://static.zybuluo.com/binbinmeng/nzsekqd02hlfwifgv1ywp044/image.png" alt="image.png-51.7kB"></p><p data-anchor-id="gezj">以如下二分图为例 <br>
<img src="http://static.zybuluo.com/binbinmeng/yriuzwx65bmmvmkmukc7ksfe/image.png" alt="image.png-6.7kB"> <br>
具体过程如下（描述1）： <br>
<img src="http://static.zybuluo.com/binbinmeng/u3hzn55tlf4othswffwrhaa5/image.png" alt="image.png-63.3kB"> <br>
具体过程如下（描述2）：</p><pre data-anchor-id="yvau" class="code-black"><code class="code-black">&lt;1&gt;. 初始化 ，即对于A来说，自身的重要度为满分，其他节点的重要度均为0。
&lt;2&gt;. 然后开始在图上游走。每次都是从PR不为0的节点开始游走，往前走一步。继续游走的概率是alpha，停留在当前节点的概率是(1-alpha)。
    &lt;2.1&gt;. 第一次游走， 从A节点以各自50%的概率走到了a和c，这样a和c就分得了A的部分重要度α*PR(A)*0.5。第一次游走结束后PR不为0的节点有A a c。
    &lt;2.2&gt;. 第二次游走，分别从节点A a c开始，往前走一步。这样节点a分得A 的重要度，节点c分得A 的重要度，节点A分得a 的重要度，节点A分得c 的重要度，节点B分得a 的重要度，节点B分得c 的重要度，节点C分得c 的重要度。最后要加上(1-α)。
</code></pre><p data-anchor-id="c7mv">程序实现：</p><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="vcih" style=""><ol class="linenums"><li class="L0"><code><span class="str">'''</span></code></li><li class="L1"><code><span class="str">G：二分图   alpha:随机游走的概率   root：游走的初始节点     max_step；最大走动步数</span></code></li><li class="L2"><code><span class="str">'''</span></code></li><li class="L3"><code><span class="kwd">def</span><span class="pln"> </span><span class="typ">PersonalRank</span><span class="pun">(</span><span class="pln">G</span><span class="pun">,</span><span class="pln"> alpha</span><span class="pun">,</span><span class="pln"> root</span><span class="pun">,</span><span class="pln"> max_step</span><span class="pun">):</span></code></li><li class="L4"><code><span class="pln">    rank </span><span class="pun">=</span><span class="pln"> dict</span><span class="pun">()</span><span class="pln">  </span></code></li><li class="L5"><code><span class="pln">    rank </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="pln">x</span><span class="pun">:</span><span class="lit">0</span><span class="pln"> </span><span class="kwd">for</span><span class="pln"> x </span><span class="kwd">in</span><span class="pln"> G</span><span class="pun">.</span><span class="pln">keys</span><span class="pun">()}</span></code></li><li class="L6"><code><span class="pln">    rank</span><span class="pun">[</span><span class="pln">root</span><span class="pun">]</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> </span><span class="lit">1</span><span class="pln">  </span></code></li><li class="L7"><code><span class="pln">    </span><span class="com">#开始迭代  </span></code></li><li class="L8"><code><span class="pln">    </span><span class="kwd">for</span><span class="pln"> k </span><span class="kwd">in</span><span class="pln"> range</span><span class="pun">(</span><span class="pln">max_step</span><span class="pun">):</span><span class="pln">  </span></code></li><li class="L9"><code><span class="pln">        tmp </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="pln">x</span><span class="pun">:</span><span class="lit">0</span><span class="pln"> </span><span class="kwd">for</span><span class="pln"> x </span><span class="kwd">in</span><span class="pln"> G</span><span class="pun">.</span><span class="pln">keys</span><span class="pun">()}</span><span class="pln">  </span></code></li><li class="L0"><code><span class="pln">        </span><span class="com">#取节点i和它的出边尾节点集合ri  </span></code></li><li class="L1"><code><span class="pln">        </span><span class="kwd">for</span><span class="pln"> i</span><span class="pun">,</span><span class="pln"> ri </span><span class="kwd">in</span><span class="pln"> G</span><span class="pun">.</span><span class="pln">items</span><span class="pun">():</span><span class="pln">  </span><span class="com">#i是顶点。ri是与其相连的顶点极其边的权重</span></code></li><li class="L2"><code><span class="pln">            </span><span class="com">#取节点i的出边的尾节点j以及边E(i,j)的权重wij, 边的权重都为1，在这不起实际作用  </span></code></li><li class="L3"><code><span class="pln">            </span><span class="kwd">for</span><span class="pln"> j</span><span class="pun">,</span><span class="pln"> wij </span><span class="kwd">in</span><span class="pln"> ri</span><span class="pun">.</span><span class="pln">items</span><span class="pun">():</span><span class="pln">   </span><span class="com">#j是i的连接顶点，wij是权重</span></code></li><li class="L4"><code><span class="pln">                </span><span class="com">#i是j的其中一条入边的首节点，因此需要遍历图找到j的入边的首节点，  </span></code></li><li class="L5"><code><span class="pln">                </span><span class="com">#这个遍历过程就是此处的2层for循环，一次遍历就是一次游走  </span></code></li><li class="L6"><code><span class="pln">                tmp</span><span class="pun">[</span><span class="pln">j</span><span class="pun">]</span><span class="pln"> </span><span class="pun">+=</span><span class="pln"> alpha </span><span class="pun">*</span><span class="pln"> rank</span><span class="pun">[</span><span class="pln">i</span><span class="pun">]</span><span class="pln"> </span><span class="pun">/</span><span class="pln"> </span><span class="pun">(</span><span class="lit">1.0</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> len</span><span class="pun">(</span><span class="pln">ri</span><span class="pun">))</span><span class="pln">  </span></code></li><li class="L7"><code><span class="pln">        </span><span class="com">#我们每次游走都是从root节点出发，因此root节点的权重需要加上(1 - alpha)  </span></code></li><li class="L8"><code><span class="pln">        </span><span class="com">#在《推荐系统实践》上，作者把这一句放在for j, wij in ri.items()这个循环下，我认为是有问题。  </span></code></li><li class="L9"><code><span class="pln">        tmp</span><span class="pun">[</span><span class="pln">root</span><span class="pun">]</span><span class="pln"> </span><span class="pun">+=</span><span class="pln"> </span><span class="pun">(</span><span class="lit">1</span><span class="pln"> </span><span class="pun">-</span><span class="pln"> alpha</span><span class="pun">)</span><span class="pln">  </span></code></li><li class="L0"><code><span class="pln">        rank </span><span class="pun">=</span><span class="pln"> tmp  </span></code></li><li class="L1"><code></code></li><li class="L2"><code><span class="pln">        </span><span class="com">#输出每次迭代后各个节点的权重  </span></code></li><li class="L3"><code><span class="pln">        </span><span class="kwd">print</span><span class="pln"> </span><span class="str">'iter:  '</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> str</span><span class="pun">(</span><span class="pln">k</span><span class="pun">)</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="str">"\t"</span><span class="pun">,</span><span class="pln">  </span></code></li><li class="L4"><code><span class="pln">        </span><span class="kwd">for</span><span class="pln"> key</span><span class="pun">,</span><span class="pln"> value </span><span class="kwd">in</span><span class="pln"> rank</span><span class="pun">.</span><span class="pln">items</span><span class="pun">():</span><span class="pln">  </span></code></li><li class="L5"><code><span class="pln">            </span><span class="kwd">print</span><span class="pln"> </span><span class="str">"%s:%.3f, \t"</span><span class="pun">%(</span><span class="pln">key</span><span class="pun">,</span><span class="pln"> value</span><span class="pun">),</span><span class="pln">  </span></code></li><li class="L6"><code><span class="pln">        </span><span class="kwd">print</span><span class="pln">  </span></code></li><li class="L7"><code></code></li><li class="L8"><code><span class="pln">    </span><span class="kwd">return</span><span class="pln"> rank  </span></code></li><li class="L9"><code></code></li><li class="L0"><code></code></li><li class="L1"><code><span class="str">'''</span></code></li><li class="L2"><code><span class="str">主函数，G表示二分图，‘A’表示节点，后边对应的字典的key是连接的顶点，value表示边的权重</span></code></li><li class="L3"><code><span class="str">'''</span></code></li><li class="L4"><code><span class="kwd">if</span><span class="pln"> __name__ </span><span class="pun">==</span><span class="pln"> </span><span class="str">'__main__'</span><span class="pun">:</span></code></li><li class="L5"><code><span class="pln">    G </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="str">'A'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'a'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'c'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">},</span><span class="pln">  </span></code></li><li class="L6"><code><span class="pln">         </span><span class="str">'B'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'a'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'b'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'c'</span><span class="pun">:</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'d'</span><span class="pun">:</span><span class="lit">1</span><span class="pun">},</span><span class="pln">  </span></code></li><li class="L7"><code><span class="pln">         </span><span class="str">'C'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'c'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'d'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">},</span><span class="pln">  </span></code></li><li class="L8"><code><span class="pln">         </span><span class="str">'a'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'A'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'B'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">},</span><span class="pln">  </span></code></li><li class="L9"><code><span class="pln">         </span><span class="str">'b'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'B'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">},</span><span class="pln">  </span></code></li><li class="L0"><code><span class="pln">         </span><span class="str">'c'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'A'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'B'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'C'</span><span class="pun">:</span><span class="lit">1</span><span class="pun">},</span><span class="pln">  </span></code></li><li class="L1"><code><span class="pln">         </span><span class="str">'d'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="pun">{</span><span class="str">'B'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="str">'C'</span><span class="pln"> </span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pun">}}</span><span class="pln">  </span></code></li><li class="L2"><code></code></li><li class="L3"><code><span class="pln">result </span><span class="pun">=</span><span class="pln"> </span><span class="typ">PersonalRank</span><span class="pun">(</span><span class="pln">G</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.85</span><span class="pun">,</span><span class="pln"> </span><span class="str">'A'</span><span class="pun">,</span><span class="pln"> </span><span class="lit">100</span><span class="pun">)</span><span class="pln">  </span></code></li><li class="L4"><code><span class="kwd">print</span><span class="pun">(</span><span class="pln">result</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="t3ax"><img src="http://static.zybuluo.com/binbinmeng/rfo8bcioppf68d4n9o964msi/image.png" alt="image.png-61kB"> <br>
结果： <br>
<img src="http://static.zybuluo.com/binbinmeng/x8aznyfe57bxkfurk0nquyxr/image.png" alt="image.png-2.7kB" title=""> <br>
与A相关度最高的依次是 A（0.269），c（0.190），B（0.185），a（0.154），C（0.086），d（0.076），b（0.039），去除A已经连接的a,c，剩下的推荐依次为B,a,C,d,b</p><p data-anchor-id="0kwg">可以看出，用户A已经对物品a、c有过行为了，所以只对物品b、d按照重要度进行排序为{d，b}。故给A的推荐列表就是{d,b}。</p><p data-anchor-id="nrn9">上图是一个PersonalRank的例子，在这个例子中，用户A没有对物品b、 d有过行为。在最后的迭代结果中， d的访问概率大于b，因此给A的推荐列表就是{d, b}。下图同时给出了不同迭代次数后每个顶点的访问概率。从图中可以看到，每个顶点的访问概率在9次迭代之后就基本上收敛了。 <br>
<img src="http://static.zybuluo.com/binbinmeng/4dmo0rh4yaqi36ahgmhvxsz0/image.png" alt="image.png-108.2kB"> <br>
            不同次迭代中不同节点的访问概率</p><p data-anchor-id="48tk">总结 <br>
虽然PersonalRank算法可以通过随机游走进行比较好的理论解释，但该算法在时间复杂度上有明显的缺点。因为在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也较为耗时。所以PersonalRank比较适合离线计算进行备份推荐使用。</p><div class="md-section-divider"></div><h3 data-anchor-id="g5kh" id="二-利用标签数据进行推荐">二. 利用标签数据进行推荐</h3><div class="md-section-divider"></div><h4 data-anchor-id="5780" id="21-ugc标签简介">2.1. UGC标签简介</h4><p data-anchor-id="d2h5">标签应用一般分为两种:</p><pre data-anchor-id="e2n9" class="code-black"><code class="code-black"> 1)一种是让作者或者专家给物品打标签;
 2)一种是让普通用户给物品打标签，也就是UGC(User Generated Content，用 户生成的内容)的标签应用.
</code></pre><p data-anchor-id="jj51"><img src="http://static.zybuluo.com/binbinmeng/9i94d4jhyvzyyes9wl780bex/image.png" alt="image.png-39.2kB" title=""> <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-21-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -618.5051216414607 11221.001930501932 887.9124054450837" style="width: 26.062ex; height: 2.085ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">两</text><g transform="translate(797,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">种</text></g><g transform="translate(1595,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">不</text></g><g transform="translate(2393,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">同</text></g><g transform="translate(3191,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(3989,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(4787,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g><g transform="translate(5635,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">系</text></g><g transform="translate(6433,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">统</text></g><g transform="translate(7231,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(8029,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">代</text></g><g transform="translate(8827,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">表</text></g><g transform="translate(9625,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">网</text></g><g transform="translate(10423,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">站</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-21">两种不同的标签系统的代表网站</script> <br>
UGC标签系统的代表应用 <br>
UGC标签系统是很多Web 2.0网站的必要组成部分，本节将讨论使用UGC标签系统的代表网站：UGC标签系统的鼻祖美味书签（Delicious）、论文书签网站CiteULike、音乐网站Lastfm、视频网站Hulu、书和电影评论网站豆瓣等。下面将分别介绍这些应用。 <br>
Delicious <br>
美味书签（Delicous）是标签系统里的开山鼻祖了，它允许用户给互联网上的每个网页打上标签，从而通过标签的方式重新组织整个互联网。图2是Delicious中被用户打上recommender <br>
system标签最多的网页，这些网页反应了用户心目中和推荐系统最相关的网页。图3是Delicious中“豆瓣电台”这个网页被用户打的最多的标签，可以看到这些标签确实准确地描述了豆瓣电台。</p><p data-anchor-id="2cbd"><img src="http://static.zybuluo.com/binbinmeng/t13o0g437c0k6kwx16sgnao6/image.png" alt="enter image description here"></p><div class="md-section-divider"></div><p data-anchor-id="8k7m"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-22-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -716.0516853480245 22020.750270270273 985.4589691516475" style="width: 51.197ex; height: 2.317ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">图</text><use xlink:href="#MJMAIN-32" x="797" y="0"></use><use xlink:href="#MJMATHI-44" x="1298" y="0"></use><use xlink:href="#MJMATHI-65" x="2126" y="0"></use><use xlink:href="#MJMATHI-6C" x="2593" y="0"></use><use xlink:href="#MJMATHI-69" x="2891" y="0"></use><use xlink:href="#MJMATHI-63" x="3237" y="0"></use><use xlink:href="#MJMATHI-69" x="3670" y="0"></use><use xlink:href="#MJMATHI-6F" x="4016" y="0"></use><use xlink:href="#MJMATHI-75" x="4501" y="0"></use><use xlink:href="#MJMATHI-73" x="5074" y="0"></use><g transform="translate(5543,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">中</text></g><g transform="translate(6341,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">被</text></g><g transform="translate(7139,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">打</text></g><g transform="translate(7937,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">上</text></g><use xlink:href="#MJMATHI-72" x="8735" y="0"></use><use xlink:href="#MJMATHI-65" x="9187" y="0"></use><use xlink:href="#MJMATHI-63" x="9653" y="0"></use><use xlink:href="#MJMATHI-6F" x="10087" y="0"></use><use xlink:href="#MJMATHI-6D" x="10572" y="0"></use><use xlink:href="#MJMATHI-6D" x="11451" y="0"></use><use xlink:href="#MJMATHI-65" x="12329" y="0"></use><use xlink:href="#MJMATHI-6E" x="12796" y="0"></use><use xlink:href="#MJMATHI-64" x="13396" y="0"></use><use xlink:href="#MJMATHI-65" x="13920" y="0"></use><use xlink:href="#MJMATHI-72" x="14386" y="0"></use><use xlink:href="#MJMATHI-73" x="14838" y="0"></use><use xlink:href="#MJMATHI-79" x="15307" y="0"></use><use xlink:href="#MJMATHI-73" x="15805" y="0"></use><use xlink:href="#MJMATHI-74" x="16274" y="0"></use><use xlink:href="#MJMATHI-65" x="16636" y="0"></use><use xlink:href="#MJMATHI-6D" x="17102" y="0"></use><g transform="translate(17981,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(18779,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g><g transform="translate(19626,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(20424,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">网</text></g><g transform="translate(21222,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">页</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-22">图2 Delicious中被打上recommender system标签的网页</script></p><p data-anchor-id="97sg"><img src="http://static.zybuluo.com/binbinmeng/1ognm1x4pg87497rb9995jx4/image.png" alt="enter image description here" title=""></p><div class="md-section-divider"></div><p data-anchor-id="0yn2"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -716.0516853480245 20159.753590733595 985.4589691516475" style="width: 46.795ex; height: 2.317ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">图</text><use xlink:href="#MJMAIN-33" x="797" y="0"></use><use xlink:href="#MJMATHI-44" x="1298" y="0"></use><use xlink:href="#MJMATHI-65" x="2126" y="0"></use><use xlink:href="#MJMATHI-6C" x="2593" y="0"></use><use xlink:href="#MJMATHI-69" x="2891" y="0"></use><use xlink:href="#MJMATHI-63" x="3237" y="0"></use><use xlink:href="#MJMATHI-69" x="3670" y="0"></use><use xlink:href="#MJMATHI-6F" x="4016" y="0"></use><use xlink:href="#MJMATHI-75" x="4501" y="0"></use><use xlink:href="#MJMATHI-73" x="5074" y="0"></use><g transform="translate(5543,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">中</text></g><use xlink:href="#MJMAIN-201C" x="6341" y="0"></use><g transform="translate(6842,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">豆</text></g><g transform="translate(7640,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">瓣</text></g><g transform="translate(8438,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">电</text></g><g transform="translate(9236,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">台</text></g><use xlink:href="#MJMAIN-201D" x="10034" y="0"></use><g transform="translate(10534,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">网</text></g><g transform="translate(11332,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">页</text></g><g transform="translate(12130,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">被</text></g><g transform="translate(12928,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">用</text></g><g transform="translate(13726,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">户</text></g><g transform="translate(14524,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">打</text></g><g transform="translate(15322,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(16120,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">最</text></g><g transform="translate(16918,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">多</text></g><g transform="translate(17716,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(18514,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(19311,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-23">图3 Delicious中“豆瓣电台”网页被用户打的最多的标签</script></p><p data-anchor-id="vclu">CiteULike <br>
CiteULike是一个著名的论文书签网站，它允许研究人员提交或者收藏他们感兴趣的论文，给论文打标签，从而帮助用户更好地发现和自己研究领域相关的优秀论文。我们知道，研究人员搜索自己研究领域值得参考的论文是很费时费力的工作，而CiteULike通过群体智能，让每个研究人员对自己了解的论文进行标记，从而帮助用户更好更快地发现自己感兴趣的论文。图4展示了CiteULike中一篇被用户打的标签最多的有关推荐系统评测的文章，可以发现，最多的两个标签是collaborative-filtering（协同过滤）和evaluate（评测），确实比较准确地反应了这篇论文的主要内容。 <br>
<img src="http://static.zybuluo.com/binbinmeng/5bfhj5ibv0ec1q2a62d7xf3a/image.png" alt="enter image description here" title=""></p><div class="md-section-divider"></div><p data-anchor-id="n6pl"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-24-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -726.0516853480245 12448.312355212356 995.4589691516475" style="width: 28.958ex; height: 2.317ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">图</text><use xlink:href="#MJMAIN-34" x="797" y="0"></use><use xlink:href="#MJMATHI-43" x="1298" y="0"></use><use xlink:href="#MJMATHI-69" x="2058" y="0"></use><use xlink:href="#MJMATHI-74" x="2404" y="0"></use><use xlink:href="#MJMATHI-65" x="2765" y="0"></use><use xlink:href="#MJMATHI-55" x="3232" y="0"></use><use xlink:href="#MJMATHI-4C" x="3999" y="0"></use><use xlink:href="#MJMATHI-69" x="4681" y="0"></use><use xlink:href="#MJMATHI-6B" x="5026" y="0"></use><use xlink:href="#MJMATHI-65" x="5548" y="0"></use><g transform="translate(6014,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">中</text></g><g transform="translate(6812,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">一</text></g><g transform="translate(7610,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">篇</text></g><g transform="translate(8408,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">论</text></g><g transform="translate(9206,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">文</text></g><g transform="translate(10004,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(10802,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(11600,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-24">图4 CiteULike中一篇论文的标签</script></p><p data-anchor-id="o1yb">Lastfm <br>
Lastfm是一家著名的音乐网站，它通过分析用户的听歌行为来预测用户对音乐的兴趣，从而给用户推荐个性化的音乐。作为多媒体，音乐不像文本那样可以很容易地分析它的内容信息。为了在不进行复杂的音频分析的情况下获得音乐的内容信息，Lastfm引用了标签系统，让用户用标签标记音乐和歌手。图5展示了披头士乐队在Lastfm中的标签云（tag <br>
cloud）。从这个标签云可以看到，披头士应该是一个英国的传统摇滚乐队，流行于上世纪60年代。</p><p data-anchor-id="svkr"><img src="http://static.zybuluo.com/binbinmeng/a9w5xc3doj0hwbu76ggquksu/image.png" alt="enter image description here"></p><div class="md-section-divider"></div><p data-anchor-id="1aaz"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-25-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -726.0516853480245 12798.688185328187 995.4589691516475" style="width: 29.768ex; height: 2.317ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">图</text><use xlink:href="#MJMAIN-35" x="797" y="0"></use><use xlink:href="#MJMATHI-4C" x="1298" y="0"></use><use xlink:href="#MJMATHI-61" x="1979" y="0"></use><use xlink:href="#MJMATHI-73" x="2509" y="0"></use><use xlink:href="#MJMATHI-74" x="2978" y="0"></use><use xlink:href="#MJMATHI-66" x="3340" y="0"></use><use xlink:href="#MJMATHI-6D" x="3890" y="0"></use><g transform="translate(4769,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">中</text></g><g transform="translate(5567,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">披</text></g><g transform="translate(6365,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">头</text></g><g transform="translate(7163,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">士</text></g><g transform="translate(7961,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">乐</text></g><g transform="translate(8759,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">队</text></g><g transform="translate(9557,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(10355,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(11152,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g><g transform="translate(12000,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">云</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-25">图5 Lastfm中披头士乐队的标签云</script></p><p data-anchor-id="8red">豆瓣 <br>
豆瓣是中国著名的评论和社交网站，同时也是中国个性化推荐邻域的领军企业之一。豆瓣在个性化推荐领域进行了广泛的尝试，标签系统也是他们尝试的领域之一。他们允许用户对图书和电影进行标签，从而获得图书和电影的内容信息，并用这种信息来改善他们的推荐效果。图7展示了《数据挖掘导论》在豆瓣被用户标记的情况。如图7所示，最多的几个标签分别是：数据挖掘、计算机、计算机科学、数据分析、IT数据分析。这些标签准确地反应了这本书的内容信息。</p><p data-anchor-id="mfxx"><img src="http://static.zybuluo.com/binbinmeng/2mkcn8gjbdpdlua4m07oae3c/image.png" alt="enter image description here" title=""></p><div class="md-section-divider"></div><p data-anchor-id="fevj"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-26-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -687.0516853480245 17307.067335907337 956.4589691516475" style="width: 40.193ex; height: 2.201ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">图</text><use xlink:href="#MJMAIN-36" x="797" y="0"></use><g transform="translate(1298,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">豆</text></g><g transform="translate(2096,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">瓣</text></g><g transform="translate(2894,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">读</text></g><g transform="translate(3692,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">书</text></g><g transform="translate(4490,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">中</text></g><g transform="translate(5288,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">《</text></g><g transform="translate(6086,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">数</text></g><g transform="translate(6884,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">据</text></g><g transform="translate(7681,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">挖</text></g><g transform="translate(8479,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">掘</text></g><g transform="translate(9277,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">导</text></g><g transform="translate(10075,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">论</text></g><g transform="translate(10873,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">》</text></g><g transform="translate(11671,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">一</text></g><g transform="translate(12469,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">书</text></g><g transform="translate(13267,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(14065,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">常</text></g><g transform="translate(14863,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">用</text></g><g transform="translate(15661,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(16459,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-26">图6 豆瓣读书中《数据挖掘导论》一书的常用标签</script></p><p data-anchor-id="is33">Hulu <br>
Hulu是美国著名的视频网站。视频作为一种最为复杂的多媒体，获取它的内容信息是最困难的，因此，Hulu也引入了用户标签系统来让用户对电视剧和电影进行标记。图7展示了美剧《豪斯医生》的常用标签，可以看到，Hulu对标签做了分类，并展示了每一类最热门的标签。从类型（genre）看，豪斯医生是一部医学片（medical <br>
drama）；从时间看，这部剧开始于2004年；从人物看，这部美剧的主演是hugh laurie，他在剧中饰演的人物是greg house。 <br>
<img src="http://static.zybuluo.com/binbinmeng/pdtoi57w3p66fiddvvdkgzwi/image.png" alt="enter image description here"></p><div class="md-section-divider"></div><p data-anchor-id="anic"><span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-27-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -716.0516853480245 13255.564015444017 985.4589691516475" style="width: 30.811ex; height: 2.317ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">图</text><use xlink:href="#MJMAIN-37" x="797" y="0"></use><use xlink:href="#MJMATHI-48" x="1298" y="0"></use><use xlink:href="#MJMATHI-75" x="2186" y="0"></use><use xlink:href="#MJMATHI-6C" x="2759" y="0"></use><use xlink:href="#MJMATHI-75" x="3057" y="0"></use><g transform="translate(3630,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">中</text></g><g transform="translate(4428,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">《</text></g><g transform="translate(5226,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">豪</text></g><g transform="translate(6024,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">斯</text></g><g transform="translate(6822,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">医</text></g><g transform="translate(7620,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">生</text></g><g transform="translate(8418,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">》</text></g><g transform="translate(9216,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(10013,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">常</text></g><g transform="translate(10811,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">用</text></g><g transform="translate(11609,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">标</text></g><g transform="translate(12407,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">签</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-27">图7 Hulu中《豪斯医生》的常用标签</script></p><p data-anchor-id="z8js">从前面的各种应用可以看到，标签系统在各种各样的网站中（音乐、视频和社交等）都得到了广泛的应用。标签系统的最大优势在于可以发挥群体的智能，获得物品内容信息的比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统的重要资源。 <br>
我们本篇主要讨论UGC的标签应用。标签系统中的推荐问题主要有以下两个：</p><pre data-anchor-id="eoea" class="code-black"><code class="code-black">1)如何利用用户打标签的行为为其推荐物品(tag-based recommendation)?
2)如何在用户给物品打标签时为其推荐适合该物品的标签(tag recommendation)?
</code></pre><p data-anchor-id="j5m1">为了研究上面的两个问题，我们首先需要解答下面三个问题。</p><pre data-anchor-id="os6n" class="code-black"><code class="code-black"> 1)用户为什么要打标签（Why）？
 2)用户怎么打标签（How）？
 3)用户打什么样的标签（What）？
</code></pre><div class="md-section-divider"></div><h5 data-anchor-id="vi2t" id="211-用户为什么要标注">2.1.1 用户为什么要标注</h5><p data-anchor-id="64ng">在设计基于Tag的个性化推荐系统之前，我们需要深入了解用户的标注行为，知道用户为什么要标注，用户怎么标注，只有深刻地了解用户的行为，我们才能基于这个行为给用户设计出令他们满意的个性化推荐系统。</p><p data-anchor-id="9mdd">Morgan Ames研究图片分享网站中用户标注的动机问题3，他将用户标注的动机分解成两个维度。首先是社会维度，有些用户标注是为了给内容的上传者使用的，而有些用户标注是为了给广大用户使用的。令一个维度是功能维度，有些标注是为了更好地组织内容，方便用户将来的查找，而另一些标注是为了传达某种信息，比如照片的拍摄时间和地点等。</p><div class="md-section-divider"></div><h5 data-anchor-id="44cz" id="212-用户如何打标签">2.1.2 用户如何打标签</h5><p data-anchor-id="iqtl">在互联网中，尽管每个用户的行为看起来是随机的，但其实这些表面随机的行为的背后蕴含着很多规律。在这一节中，我们通过研究美味书签的数据集，来发现用户标注行为中的一些统计规律。</p><p data-anchor-id="4sfn">德国的研究人员公布过一个很庞大的美味书签的数据集4，该数据集包含了2003年9月到2007年12月美味书签用户4.2亿条标签行为记录。本节选用该数据集2007年一整年的数据进行分析，对该数据集的统计特性进行研究。</p><p data-anchor-id="5rpz">本节将统计数据集的以下信息:</p><pre data-anchor-id="3u9c" class="code-black"><code class="code-black">1)用户活跃度的分布。
2)物品流行度的分布。
3)标签热门度的分布。
4)用户标签行为随时间演化的曲线。
5)用户相隔一段时间兴趣变化的情况。
6)物品的生命周期。
</code></pre><div class="md-section-divider"></div><h5 data-anchor-id="thpx" id="213-用户打什么样的标签">2.1.3 用户打什么样的标签</h5><p data-anchor-id="oakj">用户在看到一个物品时，我们最希望他打的标签是能够准确描述物品内容属性的关键词。但用户往往不是按照我们的想法去操作，而是可能会给物品打上各种各样奇怪的标签。 <br>
Scott A. Golder 总结了美味书签上的标签，将它们分为如下的几类。</p><pre data-anchor-id="hqgj" class="code-black"><code class="code-black">1)表明物品是什么：
比如是一只鸟，就会有“鸟”这个词的标签；是豆瓣的首页，就有一个标签叫“豆瓣”；是乔布斯的首页，就会有个标签叫“乔布斯”。
2)表明物品的种类：
比如在美味书签中，表示一个网页的类别的标签包括 article（文章）、 blog（博客）、 book（图书）等。
3)表明谁拥有物品：
比如很多博客的标签中会包括博客的作者等信息。
4)表达用户的观点：
比如用户认为网页很有趣，就会有funny（有趣）的标签，认为很无聊，就会打上boring（无聊）的标签。
5)用户相关的标签：
有些标签，比如 my favorite（我最喜欢的）、my comment（我的评论）等。
6)用户的任务：
比如 to read（即将阅读）、 job search（找工作）等。
很多不同的网站也设计了自己的标签分类系统，比如Hulu对视频的标签就做了分类。
</code></pre><p data-anchor-id="l8mg"><img src="http://static.zybuluo.com/binbinmeng/vzz0tpllxv59s9c21gkz03bg/image.png" alt="image.png-193.2kB"> <br>
图8是著名的美剧《豪斯医生》的标签。可以看到，Hulu将电视剧的标签分成了几类。</p><pre data-anchor-id="496q" class="code-black"><code class="code-black">类型（Genre）：
主要表示这个电视剧的类别，比如《豪斯医生》是属于医学剧情片（medical drama），同时有喜剧（comedy）、悬疑（mystery）的成分。
时间（Time）：
主要包括电视剧发布的时间，有时也包括电视剧中事件发生的时间，比如是二战期间，或者是上世纪90年代。
人物（People）：
主要包括电视剧的导演、演员和剧中重要人物等。
地点（Place）：
剧情发生的地点，或者是视频拍摄的地点等。
语言（Language）：
这部电视剧使用的语言。
奖项（Awards）：
这部电视剧获得的相关奖项。
其他（Details）：
包含了不能归类到上面各类的其他所有标签。
</code></pre><div class="md-section-divider"></div><h4 data-anchor-id="6s5k" id="22-基于标签的推荐">2.2 基于标签的推荐</h4><p data-anchor-id="cyj0">推荐系统的目的是联系用户的兴趣和物品，这种联系需要依赖于不同的媒介。GroupLens认为目前流行的推荐系统基本上通过三种方式来联系用户兴趣和物品。 <br>
<img src="http://static.zybuluo.com/binbinmeng/g5d4b9fehbu1l2z1fy5rveh3/image.png" alt="image.png-22.9kB" title=""> <br>
<span class="MathJax_Preview"></span><div class="MathJax_SVG_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-14-Frame" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 -618.5051216414607 12767.006640926642 887.9124054450837" style="width: 29.653ex; height: 2.085ex; vertical-align: -0.695ex; margin: 1px 0px;"><g stroke="black" fill="black" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">推</text><g transform="translate(797,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">荐</text></g><g transform="translate(1595,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">系</text></g><g transform="translate(2393,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">统</text></g><g transform="translate(3191,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">联</text></g><g transform="translate(3989,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">系</text></g><g transform="translate(4787,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">用</text></g><g transform="translate(5585,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">户</text></g><g transform="translate(6383,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">和</text></g><g transform="translate(7181,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">物</text></g><g transform="translate(7979,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">品</text></g><g transform="translate(8777,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">的</text></g><g transform="translate(9575,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">几</text></g><g transform="translate(10373,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">种</text></g><g transform="translate(11171,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">途</text></g><g transform="translate(11969,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" font-style="" font-weight="" stroke="none" transform="scale(49.87111969111969) matrix(1 0 0 -1 0 0)">径</text></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-14">推荐系统联系用户和物品的几种途径</script> <br>
三种方式解释如下：</p><pre data-anchor-id="0mt8" class="code-black"><code class="code-black">1）第一种方式是通过用户喜欢过的物品：可以给用户推荐与他喜欢过的物品相似的物品，这就是前面提到的基于物品的算法（item-based）。
2）第二种方式是通过和用户兴趣相似的其他用户：可以给用户推荐那些和他们兴趣爱好相似的其他用户喜欢的物品，这也是前面提到的基于用户的算法（user-based）。
3）第三个也是最重要的方式是通过一些特征（feature）来联系用户和物品，可以给用户推荐那些具有用户喜欢的特征的物品。这里的特征有不同的表现方式，比如可以表现为物品的属性集合（比如对于图书，属性集合就包括了作者、出版社、主题和关键词等），也可以表现为隐语义向量（latent
factor vector），这可以通过前面提出的隐语义模型（Latent Factor
Model）学习得到。
</code></pre><p data-anchor-id="nvql">该部分就重点分析方式三中的一种重要的特征表现方式：标签</p><div class="md-section-divider"></div><h5 data-anchor-id="svde" id="221-一个最简单的算法">2.2.1 一个最简单的算法</h5><p data-anchor-id="2b8k">拿到了用户标签行为数据，相信大家都可以想到一个最简单的个性化推荐算法。这个算法的描述如下所示:</p><pre data-anchor-id="w410" class="code-black"><code class="code-black">1)统计每个用户最常用的标签。
2)对于每个标签，统计被打过这个标签次数最多的物品。
3)对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。
</code></pre><p data-anchor-id="ob86">对于上面的算法，用户u对物品i的兴趣公式如下: <br>
<img src="http://static.zybuluo.com/binbinmeng/5sgcf699u7870tys349sp4gr/image.png" alt="image.png-39.2kB"> <br>
这里，B(u)是用户u打过的标签集合，B(i)是物品i被打过的标签集合，n_u,b是用户u打过标签b 的次数，n_b,i是物品i被打过标签b的次数。</p><div class="md-section-divider"></div><h5 data-anchor-id="pelu" id="222-基于tfidf的算法改进">2.2.2 基于TFIDF的算法改进</h5><p data-anchor-id="m24z">前面这个公式倾向于给热门标签对应的热门物品很大的权重，因此会造成推荐热门的物品给 用户，从而降低推荐结果的新颖性。另外，这个公式利用用户的标签向量对用户兴趣建模，其中 每个标签都是用户使用过的标签，而标签的权重是用户使用该标签的次数。这种建模方法的缺点 是给热门标签过大的权重，从而不能反应用户个性化的兴趣。 <br>
因此我们可以从两个方面对上式进行修正： <br>
1）首先，我们对热门标签进行一定的惩罚，得到下式： <br>
<img src="http://static.zybuluo.com/binbinmeng/kql83yhty4glplxukukye4lr/image.png" alt="image.png-67.8kB"> <br>
这里，分母记录了标签b被多少个不同的用户使用过。</p><p data-anchor-id="sgay">2）然后，我们还可以对热门物品进行惩罚： <br>
<img src="http://static.zybuluo.com/binbinmeng/lhzmsq1br1uqmh7mn47v00tx/image.png" alt="image.png-81.5kB"> <br>
这里，后面的分母记录了物品i被多少个不同的用户打过标签。</p><div class="md-section-divider"></div><h5 data-anchor-id="7l86" id="223-标签扩充">2.2.3 标签扩充</h5><p data-anchor-id="7j26">在前面的算法中，用户兴趣和物品的联系是通过 B(u)∩B(i) 中的标签建立的。但是，对于新用户或者新物品，这个集合( B(u)∩B(i) )中的标签数量会很少。为了提高推荐的准确率，我们 可能要对标签集合做扩展，比如若用户曾经用过“推荐系统”这个标签，我们可以将这个标签的 相似标签也加入到用户标签集合中，比如“个性化”、“协同过滤”等标签。 <br>
标签扩展的本质是对每个标签找到和它相似的标签，也就是计算标签之间的相似度。最简单的相似度可以是同义词。如果认为同一个物品上的不同标签具有某种相似度，那么当两个标签同时出现在很多物品的 标签集合中时，我们就可以认为这两个标签具有较大的相似度。对于标签b，令N(b)为有标签b的 物品的集合，n_{b,i}为给物品i打上标签b的用户数，我们可以通过如下余弦相似度公式计算标签 b和标签b'的相似度: <br>
<img src="http://static.zybuluo.com/binbinmeng/wp28msdttd76dbb0fv46aqo6/image.png" alt="image.png-93.7kB"></p><div class="md-section-divider"></div><h5 data-anchor-id="wf8m" id="224-标签清理">2.2.4 标签清理</h5><p data-anchor-id="yzcd">标签需要清理主要有两个原因：</p><pre data-anchor-id="3i6h" class="code-black"><code class="code-black">1）不是所有标签都能反应用户的兴趣
2）标签清理的另一个重要意义在于将标签作为推荐解释
</code></pre><p data-anchor-id="n0nn">标签清理的主要方法有：</p><pre data-anchor-id="0whk" class="code-black"><code class="code-black">1）去除词频很高的停止词
2）去除因词根不同造成的同义词
3）去除因分隔符造成的同义词
</code></pre><div class="md-section-divider"></div><h5 data-anchor-id="n3l4" id="225-基于图的推荐算法">2.2.5 基于图的推荐算法</h5><p data-anchor-id="n3c3">首先，我们需要将用户打标签的行为表示到一张图上。我们知道，图是由顶点、边和边上的 权重组成的。而在用户标签数据集上，有3种不同的元素，即用户、物品和标签。因此，我们需 要定义3种不同的顶点，即用户顶点、物品顶点和标签顶点。然后，如果我们得到一个表示用户u 给物品i打了标签b的用户标签行为(u,i,b)，那么最自然的想法就是在图中增加3条边，首先需要在用户u对应的顶点v(u)和物品i对应的顶点v(i)之间增加一条边(如果这两个顶点已经有边相连，那 么就应该将边的权重加1)，同理，在v(u)和v(b)之间需要增加一条边，v(i)和v(b)之间也需要边相连接。 <br>
下图是一个简单的用户—物品—标签图的例子。该图包含3个用户(A、B、C)、3个物品(a、 b、c)和3个标签(1、2、3)。在定义出用户—物品—标签图后，我们可以用基于随机游走的PersonalRank算法计算所有物品节点相对于当前用户节点在图上的相关性，然后按照相关性从大到小的排序，给用户推荐排名最高的N个物品。 <br>
<img src="http://static.zybuluo.com/binbinmeng/y6fwakk7mhg6lzc2jy7gkydk/image.png" alt="image.png-103kB"></p><div class="md-section-divider"></div><h3 data-anchor-id="5lqq" id="三-利用上下文信息进行推荐">三. 利用上下文信息进行推荐</h3><div class="md-section-divider"></div><h3 data-anchor-id="9hdv" id="四-利用社交网络数据进行推荐">四. 利用社交网络数据进行推荐</h3><div class="md-section-divider"></div><h3 data-anchor-id="j95a" id="五-冷启动问题">五. 冷启动问题</h3><div class="md-section-divider"></div><h3 data-anchor-id="xmkc" id="六-评分预测问题">六. 评分预测问题</h3><div class="md-section-divider"></div><h3 data-anchor-id="pdt7" id="七-ee问题及基本bandit算法">七. EE问题及基本Bandit算法</h3><div class="md-section-divider"></div><h3 data-anchor-id="psko" id="八-推荐系统中的常用评测指标">八. 推荐系统中的常用评测指标</h3><div class="md-section-divider"></div><h4 data-anchor-id="mu3u" id="81-精确率召回率f1值">8.1 精确率、召回率、F1值</h4><p data-anchor-id="dq44">我们首先来看一下混淆矩阵，对于二分类问题，真实的样本标签有两类，我们学习器预测的类别有两类，那么根据二者的类别组合可以划分为四组，如下表所示： <br>
<img src="http://static.zybuluo.com/binbinmeng/3r4qrpwmxnyngi175ab3pjgk/image.png" alt="image.png-19.6kB"> <br>
其中，行表示预测的label值，列表示真实label值。TP，FP，FN，TN分别表示如下意思：</p><pre data-anchor-id="47cm" class="code-black"><code class="code-black">TP（true positive）：表示样本的真实类别为正，最后预测得到的结果也为正；
FP（false positive）：表示样本的真实类别为负，最后预测得到的结果却为正；
FN（false negative）：表示样本的真实类别为正，最后预测得到的结果却为负；
TN（true negative）：表示样本的真实类别为负，最后预测得到的结果也为负.
</code></pre><p data-anchor-id="hkww">可以看到，TP和TN是我们预测准确的样本，而FP和FN为我们预测错误的样本。 <br>
基于混淆矩阵，我们可以得到如下的评测指标： <br>
准确率 <br>
准确率表示的是分类正确的样本数占样本总数的比例，假设我们预测了10条样本，有8条的预测正确，那么准确率即为80%。 <br>
用混淆矩阵计算的话，准确率可以表示为： <br>
<img src="http://static.zybuluo.com/binbinmeng/7wlvgmto427pasd00o2pu5uu/image.png" alt="image.png-13.9kB"> <br>
精确率／召回率 <br>
精确率表示预测结果中，预测为正样本的样本中，正确预测为正样本的概率； <br>
召回率表示在原始样本的正样本中，最后被正确预测为正样本的概率； <br>
二者用混淆矩阵计算如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/xkaareh8lt2jduul5967g962/image.png" alt="image.png-17.6kB"> <br>
F1值 <br>
为了折中精确率和召回率的结果，我们又引入了F-1 Score，计算公式如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/k39238c0hyeiqc5zcl4dmg7g/image.png" alt="image.png-15.6kB"></p><div class="md-section-divider"></div><h4 data-anchor-id="ic2x" id="82-auc曲线">8.2 AUC曲线</h4><p data-anchor-id="vuom">AUC定义为ROC曲线下方的面积：ROC曲线的横轴为“假正例率”（True Positive Rate,TPR)，又称为“假阳率”；纵轴为“真正例率”(False Positive Rate,FPR)，又称为“真阳率”。</p><p data-anchor-id="524j"><img src="http://static.zybuluo.com/binbinmeng/vx2dcrukb8muk6463jq1ebcs/image.png" alt="image.png-12.6kB" title=""> <br>
假阳率，简单通俗来理解就是预测为正样本但是预测错了的可能性，显然，我们不希望该指标太高。 <br>
<img src="http://static.zybuluo.com/binbinmeng/qwh6wucg0tpagoxf2x34ecxn/image.png" alt="image.png-13.9kB"> <br>
真阳率，则是代表预测为正样本但是预测对了的可能性，当然，我们希望真阳率越高越好。 <br>
下图就是我们绘制的一张ROC曲线图，曲线下方的面积即为AUC的值： <br>
<img src="http://static.zybuluo.com/binbinmeng/en95pg9xvvsk90u28oh6b18w/image.png" alt="image.png-16.2kB"> <br>
AUC还有另一种解释，就是测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score。</p><div class="md-section-divider"></div><h4 data-anchor-id="tpr2" id="83-hit-ratiohr">8.3 Hit Ratio(HR)</h4><p data-anchor-id="9e8p">在top-K推荐中，HR是一种常用的衡量召回率的指标，其计算公式如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/y8lrtewcwbqx3c6m3r24rfsx/image.png" alt="image.png-36.3kB"> <br>
分母是所有的测试集合，分子式每个用户top-K推荐列表中属于测试集合的个数的总和。举个简单的例子，三个用户在测试集中的商品个数分别是10，12，8，模型得到的top-10推荐列表中，分别有6个，5个，4个在测试集中，那么此时HR的值是 (6+5+4)/(10+12+8) = 0.5。</p><div class="md-section-divider"></div><h4 data-anchor-id="61o6" id="84-mean-average-precisionmap">8.4 Mean Average Precision(MAP)</h4><p data-anchor-id="wq8p">在了解MAP(Mean Average Precision)之前，先来看一下AP(Average Precision), 即为平均准确率。对于AP可以用这种方式理解: 假使当我们使用google搜索某个关键词，返回了10个结果。当然最好的情况是这10个结果都是我们想要的相关信息。但是假如只有部分是相关的，比如5个，那么这5个结果如果被显示的比较靠前也是一个相对不错的结果。但是如果这个5个相关信息从第6个返回结果才开始出现，那么这种情况便是比较差的。这便是AP所反映的指标，与recall的概念有些类似，不过是“顺序敏感的recall”。比如对于用户 u, 我们给他推荐一些物品，那么 u 的平均准确率定义为：</p><p data-anchor-id="1jv0"><img src="http://static.zybuluo.com/binbinmeng/yputzatyszyzpip6k715wxfg/image.png" alt="image.png-113.7kB"> <br>
用一个例子来解释AP的计算过程： <br>
<img src="http://static.zybuluo.com/binbinmeng/8ro2erm4n6o20gpvz1g4h06b/image.png" alt="image.png-100.2kB"> <br>
因此该user的AP为（1 + 0.66 + 0.5） ／ 3 = 0.72</p><p data-anchor-id="9lb1">那么对于MAP(Mean Average Precision)，就很容易知道即为所有用户 u 的AP再取均值(mean)而已。那么计算公式如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/pvnptrb39cjai1aypaswqlvg/image.png" alt="image.png-9.2kB" title=""></p><div class="md-section-divider"></div><h4 data-anchor-id="kaxq" id="85-normalized-discounted-cummulative-gainndcg">8.5 Normalized Discounted Cummulative Gain(NDCG)</h4><p data-anchor-id="gsqd">对于NDCG，我们需要一步步揭开其神秘的面纱，先从CG说起： <br>
CG <br>
我们先从CG(Cummulative Gain)说起, 直接翻译的话叫做“累计增益”。 在推荐系统中，CG即将每个推荐结果相关性(relevance)的分值累加后作为整个推荐列表(list)的得分。即 <br>
<img src="http://static.zybuluo.com/binbinmeng/3qvfi9xavam3t8yvw4npmy4a/image.png" alt="image.png-9.8kB" title=""> <br>
这里， rel-i 表示处于位置 i 的推荐结果的相关性，k 表示所要考察的推荐列表的大小。DCGCG的一个缺点是没有考虑每个推荐结果处于不同位置对整个推荐效果的影响，例如我们总是希望相关性高的结果应排在前面。显然，如果相关性低的结果排在靠前的位置会严重影响用户体验， 所以在CG的基础上引入位置影响因素，即DCG(Discounted Cummulative Gain), “Discounted”有打折，折扣的意思，这里指的是对于排名靠后推荐结果的推荐效果进行“打折处理”:</p><p data-anchor-id="e1lg"><img src="http://static.zybuluo.com/binbinmeng/c6da5d8y5t4aa05oso72kuo8/image.png" alt="image.png-15.2kB" title=""> <br>
从上面的式子可以得到两个结论：1）推荐结果的相关性越大，DCG越大。2）相关性好的排在推荐列表的前面的话，推荐效果越好，DCG越大。NDCGDCG仍然有其局限之处，即不同的推荐列表之间，很难进行横向的评估。而我们评估一个推荐系统，不可能仅使用一个用户的推荐列表及相应结果进行评估， 而是对整个测试集中的用户及其推荐列表结果进行评估。 那么不同用户的推荐列表的评估分数就需要进行归一化，也即NDCG(Normalized Discounted Cummulative Gain)。在介绍NDCG之前，还需要了解一个概念：IDCG. IDCG, 即Ideal DCG， 指推荐系统为某一用户返回的最好推荐结果列表， 即假设返回结果按照相关性排序， 最相关的结果放在最前面， 此序列的DCG为IDCG。因此DCG的值介于 (0,IDCG] ，故NDCG的值介于(0,1]，那么用户u的NDCG@K定义为： <br>
<img src="http://static.zybuluo.com/binbinmeng/3bt85m0izv2rcu6dw7rtglci/image.png" alt="image.png-15.9kB"> <br>
因此，平均NDCG计算为： <br>
<img src="http://static.zybuluo.com/binbinmeng/90wh0qysps08fpi1g12mvd9m/image.png" alt="image.png-18.9kB"> <br>
NDCG的完整案例看了上面的介绍，是不是感觉还是一头雾水，不要紧张，我们通过一个案例来具体介绍一下。假设在Baidu搜索到一个词，得到5个结果。我们对这些结果进行3个等级的分区，对应的分值分别是3、2、1，等级越高，表示相关性越高。假设这5个结果的分值分别是3、1、2、3、2。因此CG的计算结果为3+1+2+3+2 = 11。DCG的值为6.69，具体见下表：</p><p data-anchor-id="r1rj"><img src="http://static.zybuluo.com/binbinmeng/jry47a1u4qeodyoir1u7pkg8/image.png" alt="image.png-54.9kB"> <br>
理想状况下，我们的IDCG排序结果的相关性应该是3，3，2，2，1，因此IDCG为7.14(具体过程不再给出)，因此NDCG结果为6.69/7.14 = 0.94。</p><div class="md-section-divider"></div><h4 data-anchor-id="7kfl" id="86-mean-reciprocal-rank-mrr">8.6 Mean Reciprocal Rank (MRR)</h4><p data-anchor-id="w25h">MRR计算公式如下：</p><p data-anchor-id="q9cc"><img src="http://static.zybuluo.com/binbinmeng/qbxevk2m6fdqpn7cwtvxd3je/image.png" alt="image.png-7.1kB" title=""></p><p data-anchor-id="6h8i">其中|Q|是用户的个数，ranki是对于第i个用户，推荐列表中第一个在ground-truth结果中的item所在的排列位置。举个例子，有三个用户，推荐列表中正例的最小rank值分别为3，2，1，那么MRR=(1 + 0.5 + 0.33) / 3 = 0.61</p><div class="md-section-divider"></div><h4 data-anchor-id="shct" id="87-ils">8.7 ILS</h4><p data-anchor-id="nmcn">ILS是衡量推荐列表多样性的指标，计算公式如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/oo7p1n1hdr58g2241qljvj0z/image.png" alt="image.png-96.9kB"> <br>
如果S(bi,bj)计算的是i和j两个物品的相似性，如果推荐列表中物品越不相似，ILS越小，那么推荐结果的多样性越好。 <br>
本文实践了部分上面提到的评价指标，git地址为：<a href="https://github.com/princewen/tensorflow_practice/tree/master/recommendation/Basic-Evaluation-metrics" target="_blank">https://github.com/princewen/tensorflow_practice/tree/master/recommendation/Basic-Evaluation-metrics</a></p><div class="md-section-divider"></div><h2 data-anchor-id="mwaz" id="高级篇">高级篇</h2><p data-anchor-id="tcc1">在高级篇中，我们试图从原理上进行推导、理解各个深度CTR预估模型之间的相互关系，知其然也知其所以然。 <br>
推演的核心思路：“通过设计网络结构进行组合特征的挖掘。” <br>
具体来说有两条：其一是从FM开始推演其在深度学习上的各种推广（对应下图的红线），另一条是从embedding+MLP自身的演进特点结合CTR预估本身的业务场景进行推演（对应下图黑线部分）。 <br>
<img src="http://static.zybuluo.com/binbinmeng/7aid3weamcx1qztsalrxvyy2/image.png" alt="image.png-224.1kB"> <br>
<a href="https://blog.csdn.net/longxinchen_ml/article/details/81031736" target="_blank">https://blog.csdn.net/longxinchen_ml/article/details/81031736</a></p><div class="md-section-divider"></div><h3 data-anchor-id="ey4h" id="一fm模型理论和实践">一.FM模型理论和实践</h3><div class="md-section-divider"></div><h4 data-anchor-id="gcja" id="11-fm背景">1.1 FM背景</h4><p data-anchor-id="dm3s">在计算广告和推荐系统中，CTR预估(click-through rate)是非常重要的一个环节，判断一个商品的是否进行推荐需要根据CTR预估的点击率来进行。在进行CTR预估时，除了单特征外，往往要对特征进行组合。对于特征组合来说，业界现在通用的做法主要有两大类：FM系列与Tree系列。今天，我们就来讲讲FM算法。 <br>
 在计算广告领域，点击率CTR（click-through rate）和转化率CVR（conversion rate）是衡量广告流量的两个关键指标。准确的估计CTR、CVR对于提高流量的价值，增加广告收入有重要的指导作用。预估CTR/CVR，业界常用的方法有人工特征工程 + LR(Logistic Regression)、GBDT(Gradient Boosting Decision Tree) + LR、FM（Factorization Machine）和FFM（Field-aware Factorization Machine）模型。在这些模型中，FM和FFM近年来表现突出，分别在由Criteo和Avazu举办的CTR预测竞赛中夺得冠军。 <br>
CTR预估本质是一个二分类问题，以移动端展示广告推荐为例，依据日志中的用户侧的信息（比如年龄，性别，国籍，手机上安装的app列表）、广告侧的信息（广告id，广告类别，广告标题等）、上下文侧信息（渠道id等），去建模预测用户是否会点击该广告。 <br>
【FM和FFM模型是最近几年提出的模型，凭借其在数据量比较大并且特征稀疏的情况下，仍然能够得到优秀的性能和效果的特性，屡次在各大公司举办的CTR预估比赛中获得不错的战绩。美团点评技术团队在搭建DSP的过程中，探索并使用了FM和FFM模型进行CTR和CVR预估，并且取得了不错的效果。】</p><div class="md-section-divider"></div><h4 data-anchor-id="z3pc" id="12-one-hot编码带来的问题">1.2 one-hot编码带来的问题</h4><p data-anchor-id="xui8">FM（Factorization Machine）是由Konstanz大学Steffen Rendle（现任职于Google）于2010年最早提出的。FM因子分解机(Factorization Machine)主要是为了解决数据稀疏的情况下，特征怎样组合的问题。以一个广告分类的问题为例，根据用户与广告位的一些特征，来预测用户是否会点击广告。数据如下：(本例来自美团技术团队分享的paper)</p><p data-anchor-id="lqtx"><img src="http://static.zybuluo.com/binbinmeng/g7j0nyfn00moac3kshyfguzz/image.png" alt="image.png-27.2kB"> <br>
clicked是分类值，表明用户有没有点击该广告。1表示点击，0表示未点击。而country,day,ad_type则是对应的特征。对于这种categorical特征，一般都是进行one-hot编码处理。</p><p data-anchor-id="ihli">将上面的数据进行one-hot编码以后，就变成了下面这样 ： <br>
<img src="http://static.zybuluo.com/binbinmeng/65chh0hj3gpzfstwpi9fy90h/image.png" alt="image.png-37.8kB"> <br>
因为是categorical特征，所以经过one-hot编码以后，不可避免的样本的数据就变得很稀疏。举个非常简单的例子，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。由此可见，数据的稀疏性，是我们在实际应用场景中面临的一个非常常见的挑战与问题。 <br>
one-hot编码带来的另一个问题是特征空间变大。同样以上面淘宝上的item为例，将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间一下子暴增一百万。所以大厂动不动上亿维度，就是这么来的。</p><div class="md-section-divider"></div><h4 data-anchor-id="dg2p" id="13-对特征进行组合">1.3 对特征进行组合</h4><p data-anchor-id="yu19">普通的线性模型，我们都是将各个特征独立考虑的，并没有考虑到特征与特征之间的相互关系。但实际上，大量的特征之间是有关联的。最简单的以电商为例，一般女性用户看化妆品服装之类的广告比较多，而男性更青睐各种球类装备。那很明显，女性这个特征与化妆品类服装类商品有很大的关联性，男性这个特征与球类装备的关联性更为密切。如果我们能将这些有关联的特征找出来，显然是很有意义的。 <br>
FM出现之前的传统的处理方法是人工特征工程加上线性模型（如逻辑回归Logistic Regression）。为了提高模型效果，关键技术是找到到用户点击行为背后隐含的特征组合。 <br>
但是人工进行特征组合通常会存在诸多困难，如特征爆炸、特征难以被识别、组合特征难以设计等。为了让模型自动地考虑特征之间的二阶组合信息，线性模型推广为二阶多项式（）模型： <br>
一般的线性模型为：</p><p data-anchor-id="ztfb"><img src="http://static.zybuluo.com/binbinmeng/bvpiy281b1xlyo004cjh096i/image.png" alt="![][50]。"> <br>
从上面的式子很容易看出，一般的线性模型压根没有考虑特征间的关联。为了表述特征间的相关性，我们采用多项式模型。在多项式模型中，特征xi与xj的组合用xixj表示。为了简单起见，我们讨论二阶多项式模型。具体的模型表达式如下：</p><p data-anchor-id="dzsn"><img src="http://static.zybuluo.com/binbinmeng/z1a3io1edale8tba5b23jgv3/image.png" alt="image.png-20.3kB" title=""> <br>
上式中，n表示样本的特征数量,xi表示第i个特征。 <br>
与线性模型相比，FM的模型就多了后面特征组合的部分。 <br>
其实就是对特征两两相乘（组合）构成新特征(离散化之后其实就是“且”操作)，并对每个新特征分配独立的权重，通过机器学习来自动得到这些权重。将其写成矩阵形式为： <br>
<img src="http://static.zybuluo.com/binbinmeng/rcw0gciryoa8pdkbmsto9ben/image.png" alt="image.png-10kB" title=""> <br>
其中W^(2)为二阶特征组合的权重矩阵，是对称矩阵。而这个矩阵参数非常多，为。为了降低该矩阵的维度，可以将其因子分解（Factorization）为两个低维（比如）矩阵的相乘。则此时W矩阵的参数就大幅降低，为O(nk)。公式如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/mfoj0kn8ie4gferw8q60hmg2/image.png" alt="image.png-4.1kB" title=""> <br>
FM的矩阵形式公式如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/16zn2c19gey98hljhr39ch97/image.png" alt="image.png-10.4kB" title=""></p><div class="md-section-divider"></div><h4 data-anchor-id="ndxm" id="14-fm求解">1.4 FM求解</h4><p data-anchor-id="pkcj">从上面的式子可以很容易看出，组合部分的特征相关参数共有n(n−1)/2个。但是如第二部分所分析，在数据很稀疏的情况下，满足xi,xj都不为0的情况非常少，这样将导致ωij无法通过训练得出。 <br>
为了求出ωij，我们对每一个特征分量xi引入辅助向量Vi=(vi1,vi2,⋯,vik)。然后，利用vivj^T对ωij进行求解。 <br>
<img src="http://static.zybuluo.com/binbinmeng/7c71gj1r5jxtw3mt3k4h8g4h/image.png" alt="image.png-14.9kB" title=""> <br>
那么ωij组成的矩阵可以表示为: <br>
<img src="http://static.zybuluo.com/binbinmeng/ql5w3pdx5aws6fzci89isb70/image.png" alt="image.png-9.9kB" title=""> <br>
那么，如何求解vi和vj呢？主要采用了公式： <br>
<img src="http://static.zybuluo.com/binbinmeng/ybupi7ei5t3b6yb70j5c1frx/image.png" alt="image.png-9.1kB" title=""> <br>
具体过程如下： <br>
<img src="http://static.zybuluo.com/binbinmeng/hd3d3evyqgyozruj2bo7puxm/image.png" alt="image.png-55.6kB" title=""> <br>
上面的式子中有同学曾经问我第一步是怎么推导的，其实也不难，看下面的手写过程。 <br>
<img src="http://static.zybuluo.com/binbinmeng/gim1l9e9lvu2260hes1mcx1e/image.png" alt="image.png-177kB"> <br>
经过这样的分解之后，我们就可以通过随机梯度下降SGD进行求解： <br>
<img src="http://static.zybuluo.com/binbinmeng/1e7c7q6jrdywsol1sttb550l/image.png" alt="image.png-23.1kB" title=""> <br>
关于FM公式推导还可以参见：<a href="https://www.cnblogs.com/wkang/p/9588360.html" target="_blank">https://www.cnblogs.com/wkang/p/9588360.html</a></p><div class="md-section-divider"></div><h3 data-anchor-id="zdh4" id="二ffm模型理论和实践">二.FFM模型理论和实践</h3><div class="md-section-divider"></div><h3 data-anchor-id="o7jk" id="三deepfm模型理论和实践">三.DeepFM模型理论和实践</h3><div class="md-section-divider"></div><h3 data-anchor-id="pbwx" id="四多值离散特征的embedding解决方案">四.多值离散特征的embedding解决方案</h3><div class="md-section-divider"></div><h3 data-anchor-id="7xbl" id="五deepcross-network模型理论和实践">五.Deep&amp;Cross Network模型理论和实践</h3><div class="md-section-divider"></div><h3 data-anchor-id="6swx" id="六pnn模型理论和实践">六.PNN模型理论和实践</h3><div class="md-section-divider"></div><h3 data-anchor-id="4vqk" id="七nfm模型理论和实践">七.NFM模型理论和实践</h3><div class="md-section-divider"></div><h3 data-anchor-id="xooz" id="八afm模型理论和实践">八.AFM模型理论和实践</h3><div class="md-section-divider"></div><h3 data-anchor-id="x4ah" id="九gbdtlr融合方案实战">九.GBDT+LR融合方案实战</h3><div class="md-section-divider"></div><h3 data-anchor-id="1tig" id="十神经协同过滤ncf原理及实战">十.神经协同过滤NCF原理及实战</h3><div class="md-section-divider"></div><h3 data-anchor-id="z8ms" id="十一基于强化学习的推荐理论与实践">十一.基于强化学习的推荐理论与实践</h3><p data-anchor-id="9j2g">DRN:A Deep Reinforcement Learning Framework for News Recommendation》</p><div class="md-section-divider"></div><h3 data-anchor-id="50ik" id="十二贝叶斯个性化排序bpr算法原理及实战">十二.贝叶斯个性化排序(BPR)算法原理及实战</h3><div class="md-section-divider"></div><h3 data-anchor-id="bslb" id="十三深度兴趣进化网络dien原理及实战">十三.深度兴趣进化网络DIEN原理及实战</h3><div class="md-section-divider"></div><h3 data-anchor-id="kv7l" id="十四知识图谱与推荐系统结合之dkn模型原理及实现">十四.知识图谱与推荐系统结合之DKN模型原理及实现</h3><div class="md-section-divider"></div><h3 data-anchor-id="bglv" id="十五知识图谱与推荐系统结合之ripplenet模型原理及实现">十五.知识图谱与推荐系统结合之RippleNet模型原理及实现</h3><div class="md-section-divider"></div><h3 data-anchor-id="hmkc" id="十六知识图谱与推荐系统结合之mkr模型原理及实现">十六.知识图谱与推荐系统结合之MKR模型原理及实现</h3><div class="md-section-divider"></div><h3 data-anchor-id="o9jr" id="十七协同记忆网络理论及实践">十七.协同记忆网络理论及实践</h3></div>
</body>
</html>